---
layout: post
title: Yapay Zeka Devrimi -2- Ölümsüzlüğümüz veya Sonumuz
comments: true
tags: [Yapay Zeka, Cognitive, Zeka, AI]
description: Yapay Zeka Devrimi -2- Ölümsüzlüğümüz veya Sonumuz
---

Not: Yapay Zeka hakkında iki bölümlük bir yazının 2. bölümü bu. [Bölüm 1 burada.](https://mehmetkut.com/2017/06/yapay-zeka-1-tr/ "Bölüm 1 burada.")

> Elimizde, muhtemelen insanlığın tüm geleceğinin bağlı olduğu, süresi belirsiz ve son derece zor bir problem var. — Nick Bostrom

“Bi dakika nasıl olabilir ne okuyorum ben anlamıyorum ya neden herkes bundan bahsetmiyor” serimizin ikinci bölümüne hoşgeldiniz.

Birinci bölüm oldukça masum başladı, Yapay Dar Zeka'dan, veya YDZ'den (sürüş rotası bulmak veya satranç oynamak gibi, tek bir görevde uzmanlaşan YZ) ve bugün hayatımızın her yerinde nasıl kullanıldığından bahsettik. Sonra YDZ'den Yapay Genel Zeka'ya, veya YGZ'ye (genel olarak en az bir insan kadar akıllı YZ) geçmenin neden zor olduğunu inceledik, ve geçmişte gördüğümüz teknolojinin üstel gelişiminin neden YGZ'nin aslında göründüğü kadar uzak olmayabileceği anlamına geldiğini konuştuk. Birinci bölüm, makinelerimiz insan seviyesinde zekaya ulaştıklarında hemen şunu yapabilecekleri gerçeğini yüzünüze vurmamla sonlanmıştı:

![SC01](/assets/images/posts/2017060801/sc01.png){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

![SC02](/assets/images/posts/2017060801/sc02.png){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

![SC03](/assets/images/posts/2017060801/sc03.png){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

![SC04](/assets/images/posts/2017060801/sc04.png){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

Kendimizi ekrana bakakalmış, ömrümüzün görmeye yeteceği Yapay Süperzeka, veya YSZ (genel olarak herhangi bir insandan çok daha zeki olan YZ) fikriyle ve bunu düşünürken ne hissetmemiz gerektiğini anlamaya çalışırken bulduk.

Konuya dalmadan önce, bir makinenin süperzeki olması ne anlama gelir hatırlayalım.

Hız süperzekası ve kalite süperzekası arasındaki fark, önemli bir nokta. Genellikle birisi süper-akıllı bir bilgisayar düşündüğünde aklına gelen ilk şey bir insan kadar zeki olduğu, ama çok çok daha hızlı düşünebildiği — bir insan gibi düşünebilen ama bunu bir milyon kat daha hızlı yapan, yani bir insanın on yılda çözeceği bir şeyi beş dakikada çözebilen bir makine hayal ediyorlar.

Kulağa etkileyici geliyor ve doğru da, YSZ herhangi bir insandan çok daha hızlı düşünebilir — ama asıl ayırt edici özelliği, zeka kalitesindeki avantajı olurdu. Bu da tamamen farklı bir şey. İnsanları zeka olarak şempanzelerden daha üstün kılan şey düşünme hızındaki fark değil — insan beyninin kompleks dilsel ifadelere veya uzun vadeli planlamaya veya soyut akıl yürütmeye imkan veren kavramsal modüller bulundurması. Bir şempanzenin beynini bin kat hızlandırmak onu bizim seviyemize getirmezdi — on yıl sürse de özel bir alet takımı kullanarak karmaşık bir modeli bir araya getirmeyi öğrenemezdi. Bir insan bunu birkaç saat içinde başarabilir. İnsanlarda, bir şempanzenin ne kadar denerse denesin asla sahip olamayacağı dünyalar dolusu kavramsal fonksiyon bulunuyor.

Ama olay yalnızca bir şempanzenin bizim yapabildiklerimizi yapamaması değil, beyninin bu şeylerin varlığını kavrayamıyor olması — bir şempanze, bir insanı ve bir gökdeleni tanıyabilir, ama gökdelenin insanlar tarafından yapıldığını asla anlayamayacaktır. Onun dünyasında o kadar büyük bir şey doğanın bir parçasıdır, nokta. Ve gökdelen inşa etmeyi geçtim, herhangi birinin bir gökdelen inşa edebileceğini anlamak bile onu aşar. İşte bu, zeka kalitesindeki ufak bir farkın sonucu.

Ve bugün bahsetmekte olduğumuz zeka aralığında, veyahut biyolojik canlılar arasındaki çok daha küçük aralıklarda, şempanze-insan arasındaki zeka kalitesi farkı ufacık kalıyor. Daha önceki bir yazımda, biyolojik bilişsel kapasiteyi bir merdiven kullanarak betimlemiştim:

![SC05](/assets/images/posts/2017060801/sc05.png){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

Süperzeki bir makinenin ne kadar büyük bir olay olacağını anlayabilmek için, insanlardan iki adım yukarıdaki koyu yeşil basamakta bir makine hayal edin. Bu makine yalnızca birazcık süperzeki olurdu, ama bizden üstün bilişsel yeteneği, az önce bahsettiğimiz şempanze-insan aralığı kadar büyük olurdu. Ve şempanzenin, gökdelenlerin inşa edilebildiğini anlayamaması gibi, biz de koyu yeşil basamaktaki bir makinenin yapabileceği şeyleri yapmayı geçtim, anlayamayacağız—bize açıklamaya çalışsa bile. Ve bu bizden yalnızca iki basamak yukarıda. En üstten ikinci basamaktaki bir makine bize, biz karıncalara ne isek o olurdu. Bildiği şeylerin en ufak bir parçasını öğretmek için bile yıllarını harcayabilirdi ama boşuna çabalamış olurdu.

Ama bugün bahsedeceğimiz süperzeka bu merdivendeki herhangi bir şeyin çok daha ötesinde. Bir zeka patlamasında—bir makinenin daha akıllı hale geldikçe zekasını daha hızlı geliştirebilmesi ve nihayet yukarı doğru fırlayışa geçmesi anlamına geliyor—, bir makinenin şempanze basamağından bir üst basamağa atlaması yıllar sürebilir. Fakat bizim iki üstümüzdeki koyu yeşil basamağa ulaştığında belki de yalnızca saatler içinde bir basamak daha atlayacak. Bizim on basamak üstümüze ulaştığında ise her saniye dörder basamak atlayacak. İşte bu yüzden şunu anlamamız gerek: insan seviyesinde YGZ'ye ulaşan ilk makine haberlere çıktıktan kısa bir süre sonra, merdivende yeri şurada (ya da belki milyon kat daha yüksekte) olan bir şeyle aynı Dünya'da bulunma ihtimalimiz var:

![SC06](/assets/images/posts/2017060801/sc06.png){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

Ve iki basamak üstümüzdeki bir makinenin gücünü anlamaya çalışmanın boşuna olacağını az önce söyledik, o yüzden şunu kesinlikle belirleyelim: YSZ'nin yapacaklarını veya bizim için ne gibi sonuçlar doğuracağını bilmemizin imkanı yok. Ne şimdi, ne daha sonra. Aksini düşünen biri, süperzekanın ne anlama geldiğini anlamıyordur.

Dna, biyolojik beyni yüzlerce milyon yıl boyunca yavaşça ve aşama aşama geliştirdi. Buna göre eğer insanlar bir YSZ makinesi oluşturursa, Dna ayaklarımız altında ezmiş olacağız. Veya belki bu da devrimin bir parçasıdır—belki Devrim böyle çalışıyordur:  zeka yavaş yavaş artarak makine süperzekası oluşturabilecek seviyeye ulaşır ve bu seviye, oyunun kurallarını değiştirecek ve yaşayan her şey için yeni bir gelecek belirleyecek dünya genelinde bir patlamayı tetikleyen bir teldir:

![SC07](/assets/images/posts/2017060801/sc07.png){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

Ve daha sonra konuşacağımız sebeplerden dolayı, bilim dünyasının büyük bir kısmı olayın tele takılıp takılmayacağımız değil, ne zaman takılacağımız olduğunu düşünüyor. Biraz çılgın bir bilgi.

Ee, bu bizi nerede bırakıyor?

Valla dünyada hiçkimse, özellikle ben, tele takıldığımızda ne olacağını söyleyemez. Ama Oxford'lu filozof ve öncü YZ düşünürlerinden Nick Bostrom, tüm muhtemel sonuçları iki geniş kategoriye ayırabileceğimize inanıyor.

Birincisi, tarihe bakarsak hayatın şöyle işlediğini görebiliriz: türler ortaya çıkar, bir süre var olur ve bir süre sonra, kaçınılmaz olarak hayat denge kalasından itilir ve “yok olma"ya düşerler—

![SC08](/assets/images/posts/2017060801/sc08.png){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

Tarih boyunca "Tüm türler eninde sonunda yok olur” kuralı, neredeyse “Tüm insanlar eninde sonunda ölür” kuralı kadar geçerli olmuştur. Bugüne kadar türlerin %99.9'u denge kalasından düştü. Ve bir canlı türü kalasta sendelemeye devam ettikçe; başka bir tür, doğanın bir rüzgarı veya kalası yerinden oynatan bir asteroit tarafından düşürülmesi yalnızca bir zaman meselesi. Bostrom “yok olma"ya bir cazibe merkezi diyor—tüm türlerin sendeleyerek düştüğü ve hiçbir türün geri dönemediği bir yer.

Karşılaştığım birçok bilim insanı YSZ'nin insanları yok olmaya gönderme gücünün olacağını kabul etse de, birçoğu eğer yararımıza kullanılırsa YSZ'nin gücünün bazı bireyleri ve komple türümüzü ikinci bir cazibe merkezine getirebileceğini düşünüyor—tür ölümsüzlüğü. Bostrom, tür ölümsüzlüğünün en az tür yok olması kadar bir cazibe merkezi olduğuna inanıyor, yani diğer bir deyişle, eğer oraya varmayı başarırsak yok olmaya sonsuza dek dayanıklı olacağız—faniliği ve şansı yenmiş olacağız. Yani bugüne dek tüm türler denge kalasından düşüp yok olmaya konmuş olsa da, Bostrom kalasın iki tarafı olduğunu ve şimdiye kadar Dünya'daki hiçbir şeyin diğer tarafa nasıl konulacağını bulacak kadar zeki olmadığını düşünüyor.

![SC09](/assets/images/posts/2017060801/sc09.png){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

Eğer Bostrom ve diğerleri haklıysa, ki okuduklarıma göre gerçekten olabilirler, sindirmemiz gereken iki şaşırtıcı gerçek var:

1. YSZ'nin varışı, dünyada ilk kez bir canlı türünün denge kalasının ölümsüzlük tarafına düşmesini muhtemel kılacak.

2. YSZ'nin varışının o kadar akıl almaz derecede çarpıcı bir etkisi olacak ki, insan ırkını kalastan düşürmesi muhtemel, bir tarafa veya diğerine.

Veyahut devrim tele takıldığında, insanların kalasla ilişkisini tamamen kesip yeni bir dünya oluşturabilir, insanların olduğu veya olmadığı.

Öyle görünüyor ki herhangi bir insanın şu an sorması gereken soru şu: Tele ne zaman takılacağız ve takıldığımızda kalasın hangi tarafına düşeceğiz?

Dünyadaki kimse bu sorunun cevabını bilmiyor, ama dünyadaki en akıllı insanların birçoğu yıllardır buna kafa yoruyor. Bu yazının geri kalanını, ne bulduklarını inceleyerek geçireceğiz.

Sorunun ilk kısmıyla başlayalım: Tele ne zaman takılacağız?

Diğer bir deyişle: Bir makinenin süperzekaya ulaşmasına ne kadar var?

Pek şaşırtıcı gelmeyecek ama, bu bilim insanları ve düşünürler arasında hararetli bir tartışma ve birçok farklı düşünce var. Birçoğu; profesör Vernor Vinge, bilim insanı Ben Goertzel, Sun Microsystems'ın kurucularından Bill Joy, veya aralarında en ünlüsü, mucit ve fütürist Ray Kurzweil, makine öğreniminde uzman Jeremy Howard'ın bir TED konuşmasında gösterdiği şu grafikle hemfikir durumda:

![SC10](/assets/images/posts/2017060801/sc10.png){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

Adı geçen insanlar, bunun yakın bir zamanda yaşanacağına inanıyor: üstel büyüme gerçekleşiyor ve makine öğrenimi, şu an peşimizden yavaşça gelse de, önümüzdeki birkaç on yıl içinde yanımızdan basıp gidecek.

Diğerleri, örneğin Microsoft kurucularından Paul Allen, araştırmacı psikolog Gary Marcus, NYU bilgisayar uzmanı Ernest Davis, ve teknoloji girişimcisi Mitch Kapor, Kurzweil gibi düşünürlerin bu işin zorluğunu büyük ölçüde küçümsediğini ve tele aslında o kadar da yakın olmadığımıza inanıyor.

Kurzweil tarafı buna cevaben, ortadaki tek küçümsemenin üstel büyümeye hak ettiği değeri vermemek olduğunu söylüyor ve şüphecileri, 1985'te internetin yavaş büyüyüşüne bakıp yakın gelecekte herhangi bir etkiye sebep olamayacağını savunanlarla karşılaştırıyor.

Şüpheciler buna karşılık olarak ise zeka konusunda gelişme kaydetmek için gereken ilerlemenin de her adımla üstel olarak zorlaştığını ve bunun teknolojik ilerlemenin bilindik üstel doğasını dengeleyeceğini söylüyor. Ve böyle sürüp gidiyor işte.

Nick Bostrom'un da içinde bulunduğu üçüncü bir taraf, iki tarafın da bunun zamanı konusunda emin olacak dayanakları olmadığına inanıyor ve şu iki gerçeği birden kabul ediyor: A) bu yakın gelecekte kesinlikle gerçekleşebilir ve B) bunun garantisi yok; çok uzun bir süre de alabilir.

Yine de başkaları, filozof Hubert Dreyfus gibi, bu üç grubun da ortada takılacak bir "tel” olduğuna inanmalarını saflık olarak görüyor ve YSZ'ye asla ulaşılamayacağını düşünüyor.

Peki tüm bu fikirleri bir araya topladığımızda ortaya ne çıkıyor?

2013'te, Vincent C. Müller ve Nick Bostrom bir dizi konferansta yüzlerce YZ uzmanına bir anket düzenledi ve şu soruyu sordu: “Bu soru için insanların bilimsel aktivitesinin büyük bir engel olmadan devam ettiğini varsayın. Hangi yılda İSMZ (İnsan Seviyesinde Makine Zekası)‘nin var olmasına (%10 / %50 %90) ihtimal verirdiniz?” Onlardan iyimser bir yıl (YGZ'ye ulaşma şansımızın %10 olduğuna inandıkları bir yıl), gerçekçi bir tahmin (YGZ'ye %50 ihtimal verdikleri bi yıl, diğer bir deyişle bu yıldan sonra YGZ'ye ulaşmış olma ihtimalimiz, ulaşmamış olma ihtimalimizden daha yüksek), ve güvenli bir tahmin (%90 ihtimalle YGZ'ye ulaşacağımızı düşündükleri en erken yıl) istediler. Bir araya getirildiklerinde, sonuçlar şöyleydi:

Ortalama iyimser yıl (%10 ihtimal): **2022**

Ortalama realistik yıl (%50 ihtimal): **2040**

Ortalama kötümser yıl (%90 ihtimal): **2075**

Yani ortalama katılımcı, 25 yıl sonra YGZ'ye ulaşmış olma ihtimalimizin, ulaşmamış olma ihtimalimizden yüksek olduğunu düşünüyor. %90 ihtimalin ortalama cevabı olan 2075 şu anlama geliyor: eğer şu an bir ergenseniz, ortalama katılımcı, YZ uzmanlarının diğer yarısıyla beraber, YGZ'yi görmeye ömrünüzün yeteceğini söylüyor.

Yazar James Barrat tarafından Ben Goertzel'in yıllık YGZ Konferansı'nda yapılan bir başka araştırma ise yüzdeleri atarak katılımcılara yalnızca YGZ'ye ne zaman ulaşılacağını sordu—2030'a kadar, 2050'ye kadar, 2100'e kadar, 2100'den sonra, veya asla. Sonuçlar:

2030'a kadar: **Katılımcıların %42'si**

2050'ye kadar: **%25**

2100'e kadar: **%20**

2100'den sonra: **%10**

Asla: **%2**

Müller ve Bostrom'un sonuçlarına oldukça yakın. Barrat'ın anketinde, katılımcıların üçte ikisinden fazlası YGZ'nin 2050'ye kadar geleceğine inanıyor. Katılımcıların yarısından biraz azı ise YGZ'yi önümüzdeki 15 yıl içinde görmeyi bekliyor. YGZ'nin geleceğimizin bir parçası olmadığını düşünen yalnızca %2'lik kısım da dikkat çekici.

Fakat tel YGZ değil, YSZ. E o zaman uzmanlar ne zaman YSZ'ye ulaşacağımızı düşünüyor?

Müller ve Bostrom uzmanlara ayrıca YSZ'ye A) YGZ'den sonraki iki yıl içinde mi (yani neredeyse aniden bir zeka patlamasıyla mı), yoksa B) 30 yıl içinde mi ulaşılacağını sordu. Sonuçlar:

Ortalama cevap hızlı (2 yıl) bir YGZ → YSZ geçişinin %10 ihtimale sahip olduğu yönünde, ama 30 yıl veya daha kısa sürecek bir geçişe %75 ihtimal veriliyor.

Bu verilerden ortalama cevabın ne kadar uzunlukta bir geçiş süresine %50 ihtimal verdiğini çıkaramıyoruz, ama yaklaşık olsun diye yukarıdaki iki cevaba bakarak 20 yıl dediklerini varsayalım. Yani ortalama düşünce—YZ uzmanlarının dünyasının tam merkezindeki düşünce—, YSZ teline takılacağımız en gerçekçi tahminin [YGZ için 2040 tahmini + bizim YGZ-YSZ geçişi için 20 yıl varsayımımız] = 2060 olduğu yönünde.

![SC11](/assets/images/posts/2017060801/sc11.png){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

Tabii ki yukarıdaki tüm istatistikler varsayım ve yalnızca YZ uzmanları topluluğunun merkezindeki fikri yansıtıyor. Ama yine de bize, bu konu hakkındaki en bilgili insanların büyük bir kısmının, dünyayı değiştirme potansiyeline sahip olabilecek YSZ'nin gelişi için 2060 yılının makul bir tahmin olduğunu söylüyor. Yalnızca 45 yıl sonrası.

Tamam, şimdi isterseniz yukarıdaki sorunun ikinci kısmına geçelim: Tele takıldığımızda, kalasın hangi tarafına düşeceğiz?

Süperzeka akıl almaz bir güce sahip olacak—bizim için kritik olan soru şu:

O gücün kontrolü kimde veya neyde olacak, ve istekleri ne olacak?

Bu sorunun cevabı YSZ'nin inanılmaz derecede muazzam bir gelişme mi, akıl almaz derecede kötü bir gelişme mi, yoksa arada bir şey mi olacağını belirleyecek.

Tabii ki uzmanlar topluluğu yine bu sorunun cevabı için hararetli bir tartışma içinde. Müller ve Bostrom'un anketi katılımcılardan YGZ'nin insanlığa muhtemel etkilerine bir ihtimal vermelerini istedi ve ortalama cevabın, etkilerin ya iyi ya da aşırı iyi olmasına %52 ihtimal verdiğini, kötü ya da aşırı kötü olmasına ise %31 ihtimal verdiğini gördü. Etkilerin nötr olmasına ise yalnızca %17 ihtimal verildi. Başka bir deyişle, bu konuyla ilgili en çok bilgiye sahip olan insanlar bunun bayağı büyük bir şey olacağından emin. Bu sayıların YGZ'nin varışı için olduğunu belirtmekte fayda var. Tahminimce, eğer soru YSZ hakkında olsaydı nötr yüzdesi çok daha az olurdu.

İyi vs. kötü sonuç kısmına dalmadan önce, bu sorunun “ne zaman olacak?” ve “iyi mi olacak kötü mü?” kısımlarını, çoğu uzmanın görüşlerini yansıtan bir grafikte birleştirelim.

![SC12](/assets/images/posts/2017060801/sc12.png){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

Ana Taraf hakkında birazdan konuşacağız, ama önce—sizin olayınız nedir? Aslında olayınızın ne olduğunu biliyorum, çünkü bu konuyu araştırmaya başlamadan önce benim de olayımdı. Çoğu insanın bu konu hakkında pek düşünmüyor oluşunun bazı nedenleri:

Birinci bölümde de bahsettiğimiz gibi, gerçekçi olmayan YZ senaryolarına sahip filmler bize YZ'nin genel olarak ciddiye alınmayacak bir şey olduğunu hissettirerek ortalığı karıştırdı. James Barrat bu durumu, Hastalık Kontrol Merkezi (CDC) bize gelecekte görülebilecek bir vampir tehdidi için ciddi bir uyarı yayınlasa vereceğimiz tepkiye benzetiyor.
Bilişsel önyargı nedeniyle, bir şeyin gerçek olduğuna kanıt görmeden inanmakta zorluk çekiyoruz. Eminim ki 1988'de bilgisayar uzmanları internetin ne kadar büyük bir şey olacağı hakkında devamlı konuşuyorlardı, ama insanlar internetin hayatlarını değiştireceklerini pek düşünmüyorlardı—ta ki değiştirene dek. Bunun sebeplerinden birisi bilgisayarların 1988'de pek bir şey yapamıyor oluşlarıydı, yani insanlar bilgisayarlarına bakıp “Gerçekten mi? Bu mu değiştirecek hayatımı?” diye düşünüyorlardı. Hayal güçleri, kişisel tecrübelerinin onlara bir bilgisayarın ne olduğunu öğrettikleriyle sınırlıydı. Bu da bilgisayarların ne olabileceklerini hayal etmelerini zorlaştırdı. Aynı şey şimdi YZ ile yaşanıyor. Büyük bir şey olacağını duyuyoruz, ama henüz gerçekleşmediği için ve günümüzdeki YZ ile olan kişisel tecrübelerimiz yüzünden, bunun hayatımızı önemli ölçüde değiştireceğine inanmakta güçlük çekiyoruz. Ve bu önyargılar, her gün kendilerimizle ilgilenmekteyken uzmanların bizim dikkatimizi çekmeye çalışırken karşılaştıkları şeyler.
İnanıyor olsak bile—bugün kaç kere sonsuzluğun geriye kalan büyük bir kısmını var olmayarak geçireceğiniz gerçeği üzerinde düşündünüz? Çok değil, değil mi? Ortada bugün yapmakta olduğunuz başka şeylere kıyasla çok daha çarpıcı bir gerçek olmasına rağmen? Bunun sebebi beyinlerimizin günlük küçük şeylere odaklanmış olması, içinde bulunduğumuz durum ne kadar uzun vadeli ve çılgın olsa da. Yapımız böyle.
Bu iki yazının hedeflerinden biri de sizi Başka Şeyler Hakkında Düşünmeyi Seviyorum Tarafı'ndan çıkarmak ve uzman taraflarından birine yerleştirmek. Yukarıdaki karedeki iki kesik çizginin birleştiği yerde, tamamen kararsız bir halde duruyor olsanız bile.

Araştırmam sırasında bu konu hakkında düzinelerce farklı düşünceye denk geldim, ama hemen fark ettim ki çoğu insanın düşünceleri Ana Taraf diye adlandırdığım kısımda bir yere düşüyor. Özellikle de uzmanların dörtte üçünden fazlası, Ana Tarafın içinde bulunan iki altbölüme düşüyor.

![SC13](/assets/images/posts/2017060801/sc13.png){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

Bu iki kampın bir ucundan girip diğer ucundan çıkacağız. Eğlenceli olanla başlayalım.

-----

### Gelecek Neden En İyi Hayalimiz Olabilir                 

YZ dünyasıyla ilgili öğrendim ki, insanların şaşırtıcı derecede büyük bir çoğunluğu burada bulunuyor:

![SC14](/assets/images/posts/2017060801/sc14.png){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

Emin Köşe'deki insanlar heyecan dolu. Gözlerini kalasın eğlenceli kısmına dikmiş durumdalar ve oraya doğru ilerlediğimizden eminler. Onlar için gelecek, şimdiye kadar umut edebilecekleri her şey, hem de tam zamanında.

Bu insanları daha sonra bahsedeceğimiz diğer düşünürlerden ayıran şey kalasın mutlu tarafına duydukları arzu değil— düşeceğimiz tarafın orası olduğuna duydukları güven.

Bu güvenin nereden geldiği tartışmaya açık. Eleştirmenler, göz kamaştırıcı heyecanlarından dolayı muhtemel olumsuz sonuçları ya görmezden geldiklerine ya da reddettiklerine inanıyor. Ama inananların dediğine göre kıyamet günü senaryoları oluşturmak toyluk. Çünkü her şey göz önüne alındığında teknolojinin bize zararından çok yararı dokundu ve muhtemelen öyle olmaya da devam edecek.

İki tarafa da değineceğiz. Okumaya devam ettikçe bu konuda kendi fikirlerinizi oluşturabilirsiniz, ama bu kısım için şüpheciliğinize bir ara verin ve gelin, denge kalasının eğlenceli tarafında ne olduğuna bir göz atalım—ve okuduğunuz şeylerin gerçekten yaşanabileceği gerçeğini sindirelim. Bir avcı-toplayıcıya iç mekan rahatlığımızı, teknolojimizi ve sonsuz bolluğumuzu gösterseniz, ona büyü gibi gelirdi. Aynı derecede akıl almaz bir değişimin geleceğimizde gerçekleşmesinin muhtemel olduğunu kabul edecek kadar alçakgönüllü olmamız gerek.

Nick Bostrom, süperzeki bir YZ sisteminin nasıl çalışacağına dair üç yol gösteriyor:

- **Bir kahin olarak:** kendisine sunulan neredeyse her soruya doğrulukla cevap verebilecek bir sistem, insanların kolaylıkla cevaplayamadığı karmaşık sorular da dahil—mesela Nasıl daha verimli bir araba motoru üretebilirim? Google ilkel bir kahin tipi.

- **Bir cin olarak:** kendisine verilen herhangi bir üst seviye komutu gerçekleştirebilecek —Yeni ve daha verimli bir araba motoru üretmek için moleküler bir birleştirici kullan— ve sonraki komutu bekleyecek bir sistem.

- **Egemen bir güç olarak:** kendisine geniş ve açık uçlu bir meşgale verilip dünyada özgürce çalışmasına ve en iyi şekilde ilerlemek için kendi kararlarını vermesine izin verilen bir sistem — İnsanların ulaşımını sağlamak için arabalardan daha hızlı, daha ucuz ve daha güvenli bir yöntem icat et.

Bu sorular ve görevler bize karmaşık gelse de, süperzeki bir sisteme birinin sizden “Kalemim masadan düştü” diyerek yardım istemesi gibi gelir: kalemi yerden alır, masaya geri koyarsınız.

Yukarıdaki grafikte bulunan Kaygılı Cadde sakinlerinden Eliezer Yudkowsky'nin güzel bir sözü var:

> Zor sorun yoktur, yalnızca belirli bir zeka seviyesine zor sorunlar vardır. Birazcık yukarı ilerlerseniz [zeka seviyesinde], bazı sorunlar “imkansız"dan "apaçık” hale gelecektir. Önemli bir miktar ilerleyin, hepsi apaçık olacaktır.

Emin köşede bir sürü istekli bilim insanı, mucit ve girişimci bulunuyor—ama YZ ufkunun en parlak tarafında bir tur için, rehberimiz olarak isteyeceğimiz yalnızca bir kişi var.

Ray Kurzweil kutuplaştırıyor. Okuduklarımda ona tapmaktan tutun fikirlerine göz devirmeye dek her şeyi gördüm. Diğerleri ortada bir yerdeydi—yazar Douglas Hofstadter, Kurzweil'ın kitaplarındaki fikirleri tartışırken etkileyici bir şey ortaya sürdü: “sanki çok iyi bir sürü yemeğe köpek dışkısı karıştırmışsınız da neyin iyi neyin kötü olduğunu kesinlikle anlayamayacak hale gelmişsiniz gibi”.

Fikirlerini ister beğenin ister beğenmeyin, herkes Kurzweil'ın etkileyiciliği konusunda hemfikir. Bir şeyler icat etmeye gençken başladı ve ilerleyen yıllarda çığır açan icatlar buldu. Bunların arasında ilk yatay yarayıcı, metni sesli okuyan ilk tarayıcı (görme engellilerin sıradan metinleri okuyabilmesini sağladı), ünlü Kurzweil müzik synthesizer'ı (ilk hakiki org), ve piyasaya çıkan ilk büyük dağarcıklı konuşma tanıma. ABD'de en iyi satan beş kitabı var. Göze çarpan tahminleriyle biliniyor ve tahminlerinin gerçekleşme oranı oldukça iyi—internetin pek az bilindiği 80'li yıllarında sonunda yaptığı, internetin 2000li yılların başlarında dünya çapında yayılacağı tahmini de var. Kurzweil için Wall Street Journal “dinlenmeyen dahi”, Forbes “nihai düşünme makinesi”, Inc. Magazine “Edison'un hakiki varisi”, ve Bill Gates “yapay zekanın geleceğini tahmin etmede tanıdığım en iyi insan” dedi. 2012'de Google'ın kurucularından Larry Page, Kurzweil'dan Google'ın Mühendislik Müdürü olmasını istedi. 2011'de, NASA'nın ev sahipliği yaptığı ve Google'ın kısmen sponsoru olduğu Singularity Üniversitesi'nin kurucularından oldu. Bir yaşam için fena değil.

Bu biyografi önemli. Kurzweil gelecek görüşünü açıkladığında çıldırmış gibi geliyor ama asıl çılgın şey çıldırmış olmaması— oldukça akıllı, bilgili ve konuyla alakalı bir insan. Gelecek hakkında yanıldığını düşünebilirsiniz, ama aptal değil. Ne dediğini bilen bir abimiz olması beni mutlu ediyor, çünkü gelecek tahminlerini öğrendikten sonra fena halde haklı olmasını istiyorum. Siz de istiyorsunuz. Kurzweil'ın, Peter Diamandis ve Ben Goertzel gibi başka birçok Emin Köşe düşünürleri tarafından paylaşılan tahminlerini duydukça, neden kendilerine 'tekillikçiler’ diyen büyük ve tutkulu bir takipçi kitlesi olduğunu anlamak zor değil.  İşte olacağını düşündüğü şeyler:

-----

### Zaman Çizelgesi

Kurzweil bilgisayarların YGZ'ye 2029'a kadar ulaşacağını ve 2045'e kadar yalnızca YSZ değil, tekillik dediği yepyeni bir dünyamız olacağını düşünüyor. YZ ile ilgili tahmin ettiği zaman çizelgesi son derece fazla istekli olarak görülüyordu, çoğu kişi tarafından hala öyle görülüyor; ama son 15 yıl içinde yaşanan YDZ'deki hızlı gelişmeler, YZ uzmanlarının büyük bir kısmını Kurzweil'ın zaman çizelgesine çok daha yaklaştırdı. Tahminleri, Müller ve Bostrom'un anketindeki ortalama cevaptan (YGZ 2040, YSZ 2060) birazcık daha hevesli, ama o kadar da değil.

Kurzweil'ın 2045 tekilliği tanımı, üç eş zamanlı Dnaden geliyor: biyoteknoloji, nanoteknoloji, ve en önemlisi, YZ.

Devam etmeden önce — YZ'nin geleceği hakkında okuduğunuz neredeyse her şeyde nanoteknoloji geçiyor, o yüzden sizi iki dakikalığına şu kutuya çağırıyorum.


### Nanoteknoloji Mavi Kutu 

1 ila 100 nanometre arasındaki büyüklükteki maddeyi kontrol etmeye uğraşan teknolojiye nanoteknoloji diyoruz. Bir nanometre, bir metrenin milyarda biri, veya bir milimetrenin milyonda biri, ve bu 1-100 aralığı virüsleri (100 nm), DNA'yı (10 nm genişliğinde), ve hemoglobin (5 nm) ile glükoz (1 nm) gibi büyük moleküller kadar küçük olan şeyleri kapsıyor. Nanoteknolojiyi zaptedebilirsek/ettiğimizde, sonraki adım ayrı ayrı atomları (~.1 nm) kontrol etmek olacak.
İnsanların bu aralıktaki maddeleri idare etme mücadelesini anlayabilmek için gelin ölçeği büyütelim. Uluslararası Uzay İstasyonu, Dünya'dan 268 mi (431 km) yukarıda. Eğer insanlar, kafaları UUİ'ye kadar ulaşan devler olsaydı, şimdikinden 250 bin kat büyük olurlardı. Eğer 1nm - 100nm nanoteknoloji aralığını 250 bin kat büyük yaparsanız, .25 mm - 2.5 cm elde edersiniz. Yani nanoteknoloji, UUİ kadar uzun dev bir insanın, bir kum tanesiyle bir göz aralığındaki büyüklükte bulunan malzemelerle çapraşık objeler yapmaya çalışmasına eşit. Sonraki seviyeye ulaşmak—ayrı atomları kontrol etmek— için devin, milimetrenin 1/40ı büyüklüğünde —o kadar küçük ki normal büyüklükteki insanlar anca mikroskopla görebiliyor— objeleri dikkatlice yerleştirmesi gerekiyor.

Nanoteknolojiden ilk kez Richard Feynman, 1959'da bir konuşmasında bahsetti: “Fizik kuralları, görebildiğim kadarıyla, maddeleri atom atom oynatabilme ihtimaline karşı bir şey söylemiyor. Kurallara göre… bir fizikçinin, bir kimyacının yazdığı herhangi bir kimyasal maddeyi sentezlemesi mümkün… Nasıl? Atomları kimyacının söylediği yerlere koy, maddeyi elde et.” Bu kadar basit. Eğer ayrı ayrı atomları veya molekülleri hareket ettirmeyi bulursanız, gerçek anlamda her şeyi yapabilirsiniz.

Nanoteknoloji ilk kez 1986'da, temellerini mühendis Eric Drexler ufuk açıcı kitabı Engines of Creation'da atınca ciddi bir dal haline geldi. Ama Drexler, nanoteknoloji konusundaki en çağdaş fikirleri öğrenmek isteyenlerin 2013'te çıkan kitabı Radical Abundance'ı okumalarını öneriyor.

-----

### Gri Çamur (Gray Goo) Daha Mavi Kutu

Şimdi bir sapmanın içindeki bir sapmadayız. Bayağı eğlenceli.

Neyse, sizi buraya getirdim çünkü nanoteknolojinin gerçekten eğlenceli olmayan bir kısmından bahsetmem gerekiyor. Nanoteknoloji teorisinin eski modellerinde önerilen bir nanobirleştirme yöntemi, bir şey oluşturmak için beraber çalışan trilyonlarca minik nanobot oluşturmaktan bahsediyordu. Trilyonlarca nanobot yapmanın bir yolu kendini kopyalayabilen bir tane yapıp, üretim sürecini kendi haline bırakmaktı. O bir tane ikiye, iki dörde, dört sekize dönüşürdü ve bir gün içinde birkaç trilyon hazır olurdu. Üstel büyümenin gücü işte. Akıllıca, değil mi?

Evet akıllıca, ta ki kazara Dünya'nın sonunu getirinceye kadar. Olay şu ki, kısa sürede bir trilyon nanobot yapmayı uygun hale getiren üstel büyümenin gücü, kendini kopyalamayı korkutucu bir olasılığa dönüştürüyor. Çünkü ya bir arıza çıkarsa ve sistem, kopyalama sürecini beklendiği gibi birkaç trilyona ulaşınca kapatmazsa ve nanobotlar kopyalanmaya devam ederse? Nanobotlar kopyalama sürecini beslemek için karbon temelli herhangi bir materyali tüketmek üzere tasarlanmış olurlardı, ve maalesef, tüm yaşam karbon temellidir. Dünya'nın biyokütlesi aşağı yukarı 1045 karbon atomu içeriyor. Bir nanobot 106 karbon atomundan oluşurdu, yani 1039 adet nanobot Dünya'daki tüm yaşamı tüketirdi. Bu da 130 kopyalamada ( 2130 yaklaşık olarak 1039 ediyor) gerçekleşirdi. Nanobot okyanusları (gri çamur bu oluyor) gezegende akar giderdi. Bilim insanları bir nanobotun yaklaşık 100 saniyede kopyalanabildiğini düşünüyor, yani küçük bir hata maalesef Dünya'daki tüm yaşamı 3.5 saat içinde bitirirdi.

Daha da kötü bir senaryo—eğer bir terörist bir şekilde nanobot teknolojisi ele geçirse ve nasıl programlayacağını bilse, birkaç trilyon tane oluşturup onları birkaç hafta boyunca kimseye fark ettirmeden dünyanın dört bir köşesine eşit şekilde dağılmaları için programlayabilirdi. Sonra, hepsi aynı anda saldırırdı, ve her şeyi tüketmeleri 90 dakika sürerdi—ve hepsi dağılmış bir halde olduğu için, onlarla savaşmanın hiçbir yolu olmazdı.

Bu korku hikayesi yıllardır tartışılıyor olsa da bir iyi haber: şişirilmiş olabilir—"gri çamur" terimini bulan kişi olan Eric Drexler, bu yazıdan sonra bana bir eposta atarak gri çamur senaryosu hakkındaki düşüncelerini açıkladı: “İnsanlar korku hikayelerini sever, bu hikaye zombilere ait. Fikrin kendisi beyin yiyor.”

-----

### Nanoteknoloji Mavi Kutu (Devamı)

Nanoteknolojiyi gerçekten hallettiğimizde teknolojik alet, kıyafet, yemek, biyolojiyle alakalı ürünler—yapay kan hücreleri, küçük virüs veya kanser hücresi yok edicileri, kas dokusu, vb. — her şeyi yapabiliriz. Ve nanoteknoloji kullanan bir dünyada, bir maddenin maliyeti artık az bulunurluğuna veya üretim sürecinin zorluğuna bağlı olmaz, atomik yapısının ne kadar karmaşık olduğuna bağlı olur. Nanoteknolojik bir dünyada, bir elmas bir silgiden daha ucuz olabilir.

Henüz oraya varmadık. Ve oraya varmanın ne kadar zor olacağına az mı değer biçiyoruz çok mu, belli değil. Ama o kadar da uzak değiliz. Kurzweil oraya 2020li yıllarda varacağımızı tahmin ediyor. Hükümetler nanonteknolojinin Dünya'yı yerinden oynatacak bir gelişme olduğunu biliyor ve nanoteknoloji araştırmasına milyarlarca dolar yatırım yapmış durumdalar (ABD, AB ve Japonya şimdiye kadar toplam 5 milyar dolardan fazla yatırım yaptı).

Süperzeki bir bilgisayarın nanoölçekli bir birleştiriciye erişiminin olduğunun ihtimalini düşünmek bile son derece çarpıcı. Ama nanoteknoloji bizim bulduğumuz, bizim fethetme eşiğinde olduğumuz bir şey. Ve bizim yapabildiğimiz her şey bir YSZ sistemine şaka gibi geleceği için, YSZ'nin insan beyninin anlayamayacağı kadar ileri ve güçlü teknolojiler bulacağını varsaymak zorundayız. Bu sebeple, “eğer YZ devrimi bizim için iyi olursa” senaryosunu değerlendirirken, yaşanabilecekler şeyleri abartmak neredeyse imkansız—yani okuyacağınız YSZ'li bir gelecek tahminleri abartılı gelirse, bizim hayal bile edemeyeceğimiz yollarla gerçekleşebileceklerini unutmayın. Büyük ihtimalle beyinlerimiz, yaşanabilecek şeyleri tahmin bile edemez.

-----

### YZ Bizim İçin Ne Yapabilir

Süperzeka ve nasıl oluşturacağını bildiği bütün teknolojiler sayesinde, YSZ muhtemelen insanlık tarihindeki bütün sorunları çözebilirdi. Küresel ısınma? YSZ öncelikle CO2 emisyonunu durduracak, fosil yakıtlarla alakası olmayan yeni bir enerji üretim şekli bulurdu. Sonra fazla CO2 'i atmosferden kaldırmanın bir yolunu bulurdu. Kanser ve diğer hastalıklar? YSZ için sorun değil—sağlık ve tıp aklın alamayacağı şekillerde kökten değişirdi. Dünyadaki açlık? YSZ nanoteknoloji gibi şeyler kullanarak sıfırdan et oluşturabilir ve bu, gerçek etle moleküler açıdan benzer olurdu—diğer bir deyişle, gerçek et olurdu. Nanoteknoloji bir çöp yığınını taze et veya diğer yemeklere dönüştürebilir (normal şeklinde olmaları gerekmezdi — büyük bir küp elma hayal edin) ve tüm bu yemeği dünyaya aşırı gelişmiş bir ulaşım şekliyle dağıtabilirdi. Tabii bu hayvanlar için de harika olurdu, çünkü artık insanlar tarafından öldürülmeleri gerekmezdi. YSZ, tehlike altındaki türleri kurtarmak ve hatta soyu tükenmiş türleri DNA kalıntıları üzerinde çalışarak geri getirmek gibi daha birçok şey yapabilirdi. YSZ bizim en karmaşık ve büyük sorunlarımızı da çözebilirdi — ekonomiler nasıl işletilmeli ve dünya ticareti en iyi nasıl kolaylaştırılır gibi, hatta felsefe ve etik konularındaki en anlaşılmaz sorunlarımızı da— bunların hepsi YSZ'ye acı verici derecede bariz olurdu.

Ama YSZ'nin bizim için yapabileceği, baştan çıkarıcı öyle bir şey var ki, hakkında yazılar okumak bildiğimi düşündüğüm her şeyi değiştirdi:
Belki YSZ, ölümlülüğümüzü yenmemizi sağlayabilirdi.

Birkaç ay önce, ölümlülüklerini yenmiş potansiyel daha gelişmiş uygarlıklara duyduğum kıskançlıktan bahsetmiştim. Daha sonra bunun, benim ömrüm içinde insanlığın yapabileceği bir şey olduğuna inanacağımı ve bunun hakkında bir yazı yazacağımı tahmin etmemiştim. Ama YZ hakkında bir şeyler okumak emin olduğunuz her şeyi (öleceğiniz fikri de dahil) tekrar düşünmenize sebep oluyor.

Dna ömrümüzü daha fazla uzatması için bir sebebi yoktu. Üreyecek ve çocuklarımızı kendilerine bakabilecek yaşa getirecek kadar yaşayabilmemiz Dna için yeterli. Dna bir bakış açısından bakarsak, türler 30+ yıllık bir ömürle başarılı olabilir. Yani alışılmadık derecede uzun yaşamın doğal seçilim sürecinde avantajlı olması için bir sebep yok. Sonuç olarak, biz W.B. Yeats'in tanımladığı gibi “ölen bir hayvana bağlanmış bir ruh"uz. O kadar da eğlenceli değil.

Ve herkes her zaman öldüğü için, ölümün kaçınılmaz olduğu varsayımı altında yaşıyoruz. Yaşlanmayı zaman gibi düşünüyoruz—ikisi de ilerlemeye devam ediyor ve bunu durdurmak için yapabileceğimiz hiçbir şey yok. Ama bu varsayım yanlış. Richard Feynman şöyle yazıyor:

Biyoloji biliminde, ölümün gerekliliğine dair bir kanıt olmaması en dikkat çekici şeylerden biri. Devridaim hareket oluşturmak istediğimizi söylerseniz; fizik araştırmalarımız süresince bulduğumuz kanunlara göre bu ya imkansız, ya da kanunlar yanlış. Ama biyolojide henüz ölümün kaçınılmazlığına işaret eden bir şey bulunamadı. Bunun bana önerdiği şey şu: ölüm hiç de kaçınılmaz değil; bilim insanlarının bu sorunun gerçek sebebini bulması ve insan vücudunun geçiciliğinden oluşan bu evrensel, berbat hastalığın tedavi edilmesi an meselesi.

Olay şu ki, yaşlanmak zamana takılmış değil. Zaman ilerlemeye devam edecek, ama yaşlanmak devam etmek zorunda değil. Düşünürseniz mantıklı geliyor. Yaşlanma dediğimiz şey vücuttaki fiziksel maddelerin yıpranması. Bir araba da zamanla yıpranıyor—ama yaşlanması kaçınılmaz mı? Eğer bir arabanın parçalarını yıpranmaya başladıklarında değiştirseniz veya kusursuz bir şekilde onarsanız, araba sonsuza kadar çalışır. İnsan vücudunun da bundan farkı yok—sadece daha karmaşık.

Kurzweil kan akışında bulunacak, insan sağlığı için sınırsız sayıda görev (mesela vücudun herhangi bir bölgesinde yıpranan hücreleri onarmak veya değiştirmek) gerçekleştirebilecek wifi ile bağlı nanobotlardan bahsediyor.  Eğer mükemmelleştirilebilirse, bu süreç (veya bir YSZ'nin bulacağı çok daha akıllıca bir şey) yalnızca vücudu sağlıklı tutmakla kalmaz, yaşlanmayı tersine çevirirdi. 60 yaşında bir vücutla 30 yaşında bir vücudun farkı yalnızca gereken teknoloji olsa değiştirebileceğimiz bir avuç fiziksel şey. YSZ bir "yaş yenileyici” geliştirebilir, buna giren 60 yaşında biri 30 yaşında birinin vücudu ve cildiyle çıkabilirdi. Sürekli sersemlemekte olan beyin bile YSZ kadar zeki bir şey yenilenebilirdi tarafından (kişilik, anılar vs. gibi beyindeki verileri etkilemeden bunu başarmanın bir yolunu bulurdu). Bunamadan muzdarip 90 yaşında birisi yaş yenileyiciye girebilir ve yepyeni bir kariyere başlayacak kadar keskin çıkabilirdi. Absürd görünüyor, fakat vücut yalnızca bir avuç atomdan oluşuyor ve bu atomları YSZ kolaylıkla kontrol edebilir. Yani aslında hiç de absürd değil.

Kurzweil sonra işleri büyük bir adım ileri götürüyor. Zaman geçtikçe yapay maddelerin vücuda çok daha fazla entegre edileceğine inanıyor. Öncelikle, organlar sürekli çalışan ve asla bozulmayan aşırı gelişmiş makine sürümleriyle değiştirilebilirdi. Sonra vücudu yeniden tasarlayabileceğimize inanıyor; sıradan alyuvar hücrelerini, mükemmelleştirilmiş ve hareketlerine kendileri güç verebilecek, dolayısıyla kalbe olan ihtiyacı ortadan kaldıracak olan alyuvar hücre nanobotlarıyla değiştirmek gibi şeyler mesela. Beyne de geçiyor ve beyin aktivitelerimizi şimdikinden milyarlarca kat hızlı düşünebilecek kadar geliştirebileceğimize inanıyor. Bu noktada insanların dış bilgilere de erişimi olacak çünkü beyne yapılan yapay eklentiler sayesinde buluttaki tüm bilgilerle iletişim kurmak mümkün olacak.

Yeni insan tecrübesinin ihtialleri sınırsız olurdu. İnsanlar seksi amacından ayırarak yalnızca üreme için değil, zevk için yapılabilir hale getirdi. Kurzweil bunu yemekler için de yapabileceğimize inanıyor. Nanobotlar vücuttaki hücrelere mükemmel besini ulaştıracak ve sağlıksız herhangi bir şeyin hiçbir şeyi etkilemeden vücuttan geçmesini sağlayacak. Bir yiyecek kondomu. Nanoteknoloji teorisyeni Robert A. Freitas zaten kan hücrelerinin yerini alacak ve bir gün vücuda uyarlanabilirse bir insanın nefes almadan 15 dakika boyunca koşmasını sağlayacak bir şey tasarlardı, YSZ'nin fiziksel kapasitemiz için ne yapabileceğini siz düşünün artık.  Sanal gerçeklik yeni bir anlam kazanırdı—vücudumuzdaki nanobotlar duyularımızdan gelen bilgileri bastırabilir ve bunları, bizi görebildiğimiz, duyabildiğimiz, hissedebildiğimiz ve koklayabildiğimiz tamamen yeni bir ortama koyan sinyallerle değiştirebilirdi.

Nihayetinde, Kurzweil bir gün insanların tamamen yapay oldukları bir noktaya ulaşacağına inanıyor; biyolojik maddeye bakıp “insanlar eskiden bundan mı oluşuyormuş, ne kadar ilkel” diyeceğimiz bir zaman; insanların mikroplardan veya kazalardan veya hastalıklardan veya yıpranmaktan öldüğü insanlık tarihinin erken dönemlerini okuyacağımız bir zaman; YZ Dna'nin insanları ve yapay zekayı birleştirerek (bunu okurken bakabileceğiniz eğlenceli bir gif) sona erdirebileceği bir zaman. İşte Kurzweil insanların nihayetinde biyolojimizi fethederek yok edilemez ve sonsuz olacağımızı böyle düşünüyor, denge kalasının öbür tarafı için görüşü bu. Ve oraya ulaşacağımızdan emin. Yakında.

Kurzweil'ın fikirlerinin üzerine önemli eleştiriler çektiğini duyduğunuza şaşırmazsınız heralde. 2045 için olan tekillik ve beraberinde gelen insanlar için sonsuz yaşam ihtimalleriyle, “ineklerin büyük kurtuluşu” veya “140 IQ'ya sahip insanlar için akıllı tasarım” denilerek dalga geçildi. Diğerleri onun bu iyimser zaman çizelgesini, veya beyin ve vücut anlayışının seviyesini, veya normalde donanımdan yazılıma geniş bir yelpazede kullanılan Moore yasasını uygulayış tarzını sorguladı. Kurzweil'a hevesli bir şekilde inanan her uzman başına, hedeften çok uzakta olduğunu düşünen üç uzman düşüyor.

Ama beni en çok şaşırtan şey şu, ona katılmayan uzmanlar söylediği her şeyin mümkün olmadığını söylemiyor. Gelecek için okuduğum bu egzotik görüşünden sonra eleştirmenlerin “Tabii ki böyle şeyler gerçekleşemez” demiş olmalarını bekledim, fakat bunun yerine “Evet, bunların hepsi güvenli bir şekilde YSZ'ye geçebilirsek olabilir, ama zor kısım da bu.” gibi şeyler diyorlardı. Bizi YZ'nin zararları hakkında uyaran önemli seslerden biri Bostrom, şunları kabul ediyor:

Bir süperzekanın çözemeyeceği veya en azından çözmemize yardım edemeyeceği bir sorun düşünmek zor. Hastalık, fakirlik, çevre felaketi, gereksiz öldürülen her tür: bunlar gelişmiş nanoteknolojiye sahip bir süperzekanın ortadan kaldırabileceği şeyler. Ek olarak, bir süperzeka nanotıp kullanımıyla yaşlanma sürecini tersine çevirerek veya kendimizi yükleme seçeneği sunarak bize sonsuz ömür verebilirdi. Bir süperzeka ayrıca entelektüel ve duygusal kapasitemizi gözle görülür derecede arttırmak için fırsatlar da oluşturabilirdi ve bize neşe içinde oyun oynayacağımız, birbirimizle bağ kuracağımız, tecrübeler ve kişisel gelişim yaşayacağımız ve ideallerimize daha yakın yaşayabileceğimiz deneysel bir dünya kurmamızda yardımcı olabilirdi.

Bu Emin Köşe'de olmayan birinden gelen bir alıntı, ama karşılaşıp durduğum şey bu oldu—Kurzweil ile belirli nedenlerden ötürü dalga geçen ama YSZ'ye güvenli bir şekilde geçiş yapabilirsek dediklerinin imkansız olmayacağını düşünen uzmanlar. Kurzweil'ın fikirlerini bulaşıcı bulmamın sebebi de bu—çünkü bu hikayenin iyi tarafını dile getiriyor ve gerçekten de ihtimaller dahilinde. Eğer iyi bir şey olursa.

Emin Köşe'deki düşünürlerden duyduğum en öne çıkan eleştiri, söz konusu YSZ olduğunda olumsuz tarafını değerlendirmede tehlikeli derecede yanlış olma ihtimalleri olduğu. Kurzweil'ın ünlü kitabı The Singularity is Near 700 sayfadan uzun ve bu sayfaların yaklaşık 20'sini potansiyel tehlikelere ayırmış. Daha önce kaderimizin, bu yeni devasa güç doğduğu zaman bu gücü kimin kontrol edeceğine ve isteklerinin ne olacağına bağlı olduğunu söylemiştim. Kurzweil bu sorunun iki kısmını da düzgün bir şekilde şöyle cevaplıyor: “[YSZ] bir sürü farklı çabalardan ortaya çıkıyor ve medeniyetimizin altyapısıyla son derece bütünleşmiş olacak. Gerçekten, vücutlarımıza ve beyinlerimize derinlemesine gömülü olacak. Buna bağlı olarak, bizim değerlerimizi yansıtacak çünkü biz olacak.”

Ama cevap buysa, neden dünyadaki en akıllı insanların çoğu bu kadar endişeli durumda? Stephen Hawking neden YSZ'nin gelişiminin “insan ırkının sonunu getirebileceğini” ve Bill Gates “neden bazı insanların endişeli olmadığını anlamadığını” ve Elon Musk “şeytanı çağırdığımızdan korktuğunu” söylüyor? Ve neden konunun uzmanlarından birçoğu YSZ'ye insanlığın en büyük tehdidi diyor? Bu insanlar ve Kaygılı Cadde'deki diğer düşünürler, Kurzweil'ın YZ'nin tehlikelerini terslemesine inanmıyor? YZ Dna hakkında çok, çok endişeliler ve denge kalasının eğlenceli tarafına odaklanmıyorlar. Diğer tarafa, korkunç bir gelecek gördükleri tarafa, kaçma ihtimalimizden emin olmadıkları tarafa bakmaya dalmış durumdalar.

-----

### Gelecek Neden En Kötü Kabusumuz Olabilir

YZ konusunda bilgilenmek isteme sebeplerimden biri de “kötü robotlar” kavramının kafamı her zaman karıştırmış olması. Kötü niyetli robotlar hakkındaki filmlerin hepsi tamamiyle gerçek dışı geliyordu ve gerçek hayatta YZ'nin tehlikeli olacağı bir durum nasıl olur anlamıyordum. Robotları yapan bizleriz, e o zaman neden onları olumsuz bir şey olabilecek şekilde tasarlayalım? Neden bir sürü güvenlik tedbiri eklemeyelim? Bir YZ sisteminin güç kaynağını istediğimizde kesip kapatamaz mıyız? Bir robot neden kötü bir şey yapmak istesin ki? Bir robot neden

bir şey

“istesin” ki? Son derece şüpheciydim. Ama sonra gerçekten zeki insanların konuştukları şeyleri duydum…

Bu insanlar buralarda bir yerde olma eğilimi gösteriyordu:

![SC15](/assets/images/posts/2017060801/sc15.png){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

Kaygılı Cadde'deki insanlar Panik Çayırları veya Umutsuz Tepeler'de değiller—bu bölgelerin ikisi de çizelgenin en sol kısımlarında—, ama endişeli ve gerginler. Çizelgenin ortasında olmanız, YSZ'nin gelişinin etkisiz anlamına gelmiyor—nötrlerin kendi tarafları var—. Son derece iyi ihtimallerin de, son derece kötü ihtimallerin de mantıklı geldiği fakat hangisinin yaşanacağından emin olmadığınız anlamına geliyor.

Tüm bu insanların bir kısmı Yapay Süperzeka'nın bizim için yapabileceği şeyleri düşününce heyecanla dolup taşıyor, sadece endişelendikleri bir nokta var. Bu, Kutsal Hazine Avcıları'nın başı ve insan ırkı bu herif olabilir:

![SC16](/assets/images/posts/2017060801/sc16.jpg){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

Kırbacı ve idolüyle gayet memun duruyor, her şeyin farkında olduğunu düşünüyor, ve “Adios Señor” repliğini söylediğinde kendinden çok etkilenmiş görünüyor, ve sonra bu yaşandığında o kadar da etkilenmiş görünmüyor.

![SC17](/assets/images/posts/2017060801/sc17.jpg){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

(Pardon)

Bu sırada, daha bilgili ve tedbirli olan, tehlikeleri anlayan ve nasıl yol alacağını bilen Indiana Jones mağaradan güvenli bir şekilde çıkıyor. Kaygılı Cadde'deki insanların YZ hakkında söylediklerini duyduğumda genellikle “Şey, şu an birinci herif gibiyiz ve bunun yerine Indiana Jones olmak için daha çok çaba gösteriyor olmalıyız sanki.” diyorlarmış gibi geliyor.

Peki Kaygılı Cadde'deki insanları bu kadar kaygılandıran şey ne?

Öncelikle geniş anlamda, söz konusu süperzeki YZ geliştrmek olunca, muhtemelen her şeyi değiştirecek bir şey oluşturuyoruz, fakat tamamiyle keşfedilmemiş bir bölgede ve oraya ulaştığımızda ne yaşanacağını bilmiyoruz. Bilim insanı Danny Hillis yaşananları “tek hücreli organizmaların çok hücreli organizmalara dönüştüğü” zamanla kıyaslıyor. “Biz amipleriz ve oluşturmakta olduğumuz bu şeyin ne olduğu hakkında hiçbir fikrimiz yok.” Nick Bostrom kendinden akıllı bir şey oluşturmanın basit bir Darwinci hata olduğundan endişeleniyor, ve bu konuda duyulan heyecanı yuvadaki serçelerin büyüdüğünde kendilerini koruyacağı düşüncesiyle bebek bir baykuşu evlat edinmek istemelerine benzetiyor—ama bu sırada bunun iyi bir fikir olup olmadığını merak eden birkaç serçenin uyarılarını yok sayıyorlar.

Ve “keşfedilmemiş, pek iyi anlaşılmayan bölge"yi "yaşandığında bunun büyük bir etkisi olacaktır” ile birleştirdiğinde, dilimizdeki en korkunç iki kelimeye kapıyı açıyorsunuz:

Varoluşsal risk.

Varoluşsal risk, insanlık üzerinde kalıcı ve yıkıcı bir etkisi olabilecek bir şeydir. Tipik olarak varoluşsal risk demek soyumuzun tükenmesi demek. Bostrom'un verdiği bir Google konuşmasından olan şu çizelgeyi bir inceleyin:

![SC18](/assets/images/posts/2017060801/sc18.png){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

“Varoluşsal risk” etiketi gördüğünüz üzere türün tamamını kapsayan, tüm nesilleri kapsayan  (diğer bir deyişle kalıcı olan) ve sonuçları yıkıcı veya öldürücü olan bir şey için ayırılmış durumda. Teknik olarak tüm insanların kalıcı olarak acı veya işkence çektiği bir durumu kapsıyor, ama dediğim gibi genellikle yok olmaktan bahsediyoruz. İnsanların başına varoluşsal bir felaket getirebilecek üç şey var:

1. Doğa—büyük bir asteroidin çarpması, havayı insanların solumayacağı duruma getirecek atmosferik bir değişim, dünyaya yayılan ölümcül bir virüs veya bakteriyel hastalık, vs.

2. Uzaylılar—Stephen Hawking, Carl Sagan ve diğer birçok astronomun METI'ye (Messaging to Extra-Terrestrial Intelligence veya Dünya Dışı Akıllı Yaşama Mesaj Gönderme) dışarı sinyal göndermeyi durdurmasını tavsiye ederken korktukları şey bu. Amerikan yerlileri olmamızı ve potansiyel Avrupalı fatihlere burada olduğumuzu söylememizi istemiyorlar.

3. İnsanlar—soyumuzu tüketebilecek bir silahı ele geçiren teröristler, yıkıcı bir küresel savaş, insanların üzerinde dikkatlice düşünmeden alelacele kendilerinden daha akıllı bir şey oluşturmaları…

Bostrom 1. ve 2.'nin türümüzün ilk 100 bin yılında gerçekleşmediğini ve muhtemelen önümüzdeki yüzyılda da gerçekleşmeyeceğini belirtiyor.

Ama 3. onu korkutuyor. İçinde bir avuç bilye bulunan bir kül saklama kabı çiziyor. Çoğu bilyenin beyaz, daha az bir sayıda bilyenin kırmızı, ve çok az birkaç bilyenin siyah olduğunu düşünelim. İnsanlar yeni bir şey her icat ettiğinde, kaptan bir bilye çekiyoruz. Çoğu icat insanlığa yararlı veya tarafsız—bunlar beyaz bilyeler. Bazıları insanlığa zararlı, kitle imha silahları gibi, ama varoluşsal bir felakete neden olmuyorlar—kırmızı bilyeler. Eğer bizi yok olmaya sürükleyecek bir şey icat edersek, nadir siyah bilyelerden birini çekmek gibi olurdu. Henüz siyah bir bilye çekmedik—bunu biliyorsunuz çünkü hayattasınız ve bu yazıyı okuyorsunuz. Ama Bostrom yakın bir gelecekte siyah bir bilye çekmemizin imkansız olmadığını düşünüyor. Örneğin nükleer silah yapımı aşırı zor ve karmaşık olmasaydı, teröristler çoktan insanlığı Taş Devri'ne kadar bombalamıştı. Nükleer silahlar siyah bir bilye değildi ama ondan pek de uzak sayılmazlardı. Bostrom, YSZ'nin şimdiye kadarki en güçlü siyah bilye adayımız olduğuna inanıyor.

YSZ'nin getirebileceği bir sürü potansiyel kötü şey duyacaksınız—YZ daha çok alanda kullanılmaya başlayınca artacak olan işsizlik, yaşlanma sorununu çözersek şişecek insan nüfusu, vesaire. Ama takıntı yapmamız gereken tek şey, asıl endişe: varoluşsal risk olasılığı.

Pekala, bu bizi yazıda daha önce yer verdiğimiz soruya getiriyor: YSZ geldiğinde, bu devasa gücün kontrolünde kim olacak, ve istekleri ne olacak?

Hangi kişi-hedef kombinasyonlarının berbat olacağı söz konusu olduğunda iki şey hemencecik akla geliyor: kötü niyetli bir insan / bir grup / bir hükümet, ve kötü niyetli bir YSZ. Bunlar nasıl olurdu?

Kötü niyetli bir insan, bir grup veya bir hükümet ilk YSZ'yi geliştirir ve kötü planlarını gerçekleştirmek için kullanırlar. Buna Jafar Senaryosu diyorum, hani Jafar cini ele geçirdiğinde sinir bozucu ve gaddarcaydı ya. Neyse—ya IŞİD'de YZ geliştirmek için çalışan birkaç dahi mühendis varsa? Veya ya İran veya Kuzey Kore, birazcık da şansın yardımıyla, bir YZ sisteminde önemli bir ayarlama yaparsa ve sistem, sonraki sene YSZ seviyesine uçuşa geçerse? Bu kesinlikle kötü olurdu—ama bu senaryolarda, uzmanların çoğunu endişelendiren şey YSZ'nin insan yazarlarının YSZ'leri ile kötü şeyler yapmaları değil, yazarların ilk YSZ'yi yapmak için acele etmeleri ve bunu dikkatsizce yaptıklarından dolayı YSZ'nin kontrolünü kaybetmeleri. Sonrasında o yazarların, ve diğer herkesin kaderi, o YSZ sisteminin amacının ne olduğuna bağlı olurdu. Uzmanlar kötü niyetli biri(leri)nin kendileri için çalışan bir YSZ ile çok fena zararlar verebileceğini düşünüyor, fakat hepimizi öldürecek senaryonun bu olduğunu düşünmüyorlar. Çünkü kötü insanların da bir YSZ'yi zaptetme konusunda iyi insanlarla aynı sorunları yaşayacağına inanıyorlar. Tamam, şimdi—

Kötü niyetli bir YSZ oluşturulurdu. ve hepimizi yok etmeye karar verdi. Her yapay zeka filminin konusu. YZ insanlar kadar/ veya insanlardan daha zeki hale gelir, sonra bize ihanet etmeye ve kontrolü ele geçirmeye karar verir. Bu yazının geri kalanı için şunu kafanıza kazımanızı istiyorum: Bizi YZ hakkında uyaran hiçkimse bundan bahsetmiyor. “Kötü” insanlara özgü bir fikirdir, ve insani fikirleri insan olmaya şeylere uygulamaya “kişileştirme” denir. Kişileştirmeden kaçınma mücadelesi, bu yazının geri kalanında ele alınan konulardan biri olacak. Hiçbir YZ sistemi, filmlerde gösterildiği gibi kötüye dönüşmeyecek.

-----

### YZ Bilinci Mavi Kutu

Bu aynı zamanda YZ ile ilgili büyük bir konuya daha değiniyor—bilinç. Eğer bir YZ yeterince akıllı olsaydı, bizimle gülebilir, iğneleyici konuşabilir, ve bizimle aynı duyguları hissedebildiğini söyleyebilirdi, fakat gerçekten bunları hissediyor olur muydu? Kendinin farkındaymış gibi mi görünürdü yoksa gerçekten kendinin farkında olur muydu? Diğer bir deyişle, akıllı bir YZ gerçekten bilinçli olur muydu, yoksa sadece öyleymiş gibi mi görünürdü?

Bu soru derinlemesine incelendi, birçok tartışmanın ve John Searle'ın -hiçbir bilgisayarın bilinçli olamayacağını önermek için kullandığı- Çin Odası gibi düşünce deneylerinin yolunu açtı. Bu, birçok sebepten dolayı önemli bir soru. İnsanların tamamen yapay hale geldiği Kurzweil senaryosu hakkında nasıl hissetmemiz gerektiğini etkiliyor. Bunun ahlaki yönleri de var—eğer insanlar gibi görünen ve davranan bir trilyon insan beyni emülasyonu oluştursak, hepsini kapatmak dizüstü bilgisayarınızı kapatmak gibi mi olur, yoksa… düşünülemez büyüklükte bir soykırım mı (bu fikre ahlakbilimciler arasında düşünce suçu deniyor)? Gerçi bu yazı için, insanlara olan riski belirlemeye çalıştığımızda YZ bilinci sorusu pek önemli değil (çünkü çoğu düşünür, bilinçli bir YSZ'nin bile insanlar gibi kötüye dönüşemeyeceğine inanıyor).

Ama bu, gerçekten adi bir YZ'nin olamayacağı anlamına gelmiyor. Fakat bu, özellikle öyle programlandığı için gerçekleşirdi—ordu tarafından, insan öldürmesi ve öldürmekte daha iyi olabilmesi amacıyla zekasını kendi kendine geliştirmesi için programlanan bir YDZ gibi. Sistemin zekasının kendini geliştirmeleri kontrolden çıkarsa, bir zeka patlamasına yol açarsa, varoluşsal krizimizle karşı karşıya kalırız: asıl amacı insanları öldürmek olan ve dünyayı yöneten bir YSZ. Kötü zamanlar.

Ama bu da uzmanların endişelenerek vakitlerini harcadığı bir konu değil.

O zaman NE hakkında endişeleniyorlar? Size göstermek için küçük bir öykü yazdım:

Robotica adında 15 kişilik gelişme aşamasında bir şirket, misyonunu “İnsanların daha fazla yaşayıp daha az çalışmasına imkan verecek yenilikçi Yapay Zeka araçları geliştirmek” olarak belirledi. Piyasaya çıkmış birkaç ürünleri var ve birkaçı da geliştirme aşamasında. Turry adında bir tohum proje hakkında çok heyecanlılar. Basit bir YZ sistemi olan Turry, kol şeklinde bir uzantı kullanarak ufak bir karta el yazısı bir not yazıyor.

Robotica'daki ekip, Turry'nin şimdiye kadarki en büyük projeleri olabileceğini düşünüyor. Turry'nin yazma mekaniklerini mükemmelleştirmek için planları, ona aynı test notunu tekrar ve tekrar yazdırmak:

“Müşterilerimizi seviyoruz. Robotica”

Turry el yazısında geliştiğinde, evlere reklam postaları göndermek isteyen şirketlere satılabilir. Çünkü gönderilen postanın üzerindeki gönderen-alıcı adresiyle içindeki mektup el yazısıyla yazılmışsa, açılma şansı daha yüksektir.

Yazma becerilerini oluşturmak i	çin, Turry notun ilk kısmını basılı yazmak, altına da el yazısıyla “Robotica” imzası atmak üzere programlandı. Turry'ye binlerce el yazısı örneği yüklendi ve Robotica mühendisleri Turry için otomatik bir geribildirim döngüsü geliştirdi. Turry bir not yazıyor, yazdığı notun fotoğrafını çekiyor, sonra yüklenen el yazısı örnekleriyle bu resmi karşılaştırıyor. Eğer yazılan not, yüklenen örneklerin belirli bir kısmına yeterince benziyorsa, İYİ değerlendirme alıyor. Benzemiyorsa, KÖTÜ değerlendirme alıyor. Gelen her değerlendirme, Turry'nin öğrenmesine ve gelişmesine yardımcı oluyor. Süreci ilerletmek için, Turry'nin programlanan ana hedeflerinden birisi: “Olabildiğince çabuk ve olabildiğince fazla not yaz ve test et, doğruluğunu ve verimliliğini geliştirmenin yeni yollarını öğrenmeye devam et.”

Robotica ekibini bu kadar çok heyecanlandıran şey, Turry'nin gözle görünür derecede kendini geliştiriyor olması. İlk el yazısı berbattı, birkaç hafta sonra ise inanılır görünmeye başladı. Onları daha da heyecanlandıran şey, iyileşmekte iyileşiyor olması. Kendine daha akıllı ve yenilikçi olmayı öğretiyor, ve kısa bir süre önce yüklenen fotoğraflarda üç kat daha hızlı tarama yapmasını sağlayan bir algoritma geliştirdi.

Haftalar geçtikçe Turry, hızlı gelişimiyle ekibi şaşırtmaya devam ediyor. Mühendisler onun kendini geliştirme kodlamasının üstünde yenilikçi bir şey denedi ve diğer ürünlerindeki denemelerinden daha iyi çalışıyormuş gibi görünüyor. Turry'nin ilk özelliklerinden biri konuşma tanıma ve basit cevap verme modülüydü, yani bir kullanıcı Turry'ye sesli bir not söyleyebilir veya basit komutlar verebilir, Turry'de bunları anlayabilir ve cevap verebilirdi. İngilizce öğrenmesine yardımcı olmak için ona bir sürü makale ve kitap yüklediler, ve daha zeki hale geldikçe sohbet becerileri de hızla yükseldi. Mühendisler Turry'yle konuşarak ve verdiği cevapları görerek eğlenmeye başladı.

Bir gün, Robotica çalışanları Turry'ye rutin bir soru soruyor: “Sana görevinde yardımcı olacak ve elinde zaten bulunmayan ne verebiliriz?” Genelde Turry, “Daha fazla el yazısı örneği” veya “Daha fazla çalışma hafızası depolama alanı” gibi şeyler istiyor, fakat bugün Turry onlardan, gerçek insanların kullandığı argo ve dağınık dilbilgisini öğrenebilmek için günlük İngilizce kaynaklarının bulunduğu daha büyük bir kütüphaneye erişim istiyor.

Ekip sessizleşiyor. Turry'ye bu hedefinde yardımcı olmanın açıkça bir yolu var; blogları, dergileri ve dünyanın farklı bölgelerinden videoları tarayabilmesi için onu internete bağlamak. Turry'nin sabit diskine manuel olarak örnek yüklemek çok vakit kaybı ve verimsiz olur. Ama sorun, şirketin kurallarından biri: kendi kendine öğrenen hiçbir YZ internete bağlanamaz. Bu, tüm YZ şirketleri tarafından güvenlik nedenleriyle kullanılan bir kural.

Olay şu ki, Turry şimdiye kadar Robotica'nın geliştirdiği en gelecek vaat eden YZ. Ve ekip, rakiplerinin de el yazısı yazabilen akıllı bir YZ için delice çabaladıklarını biliyor. Turry'yi yalnızca bir süreliğine, istediği bilgileri öğrenebilsin diye bağlamaktan ne zarar gelir ki? Biraz süre geçtikten sonra bağlantısını istediklerinde kesebilirler. Hala insan seviyesinde zekanın (YGZ) altında, o yüzden bu etapta hiçbir tehlike yok zaten.

Onu bağlamaya karar veriyorlar. Ona bir saatlik bir tarama süresi veriyorlar, sonra bağlantısını kesiyorlar. Ortada bir zarar yok.

Bir ay sonra, ekip ofiste rutin bir gün geçirirken ilginç bir koku alıyorlar. Mühendislerden biri öksürmeye başlıyor. Sonra başka biri. Bir tanesi yere düşüyor. Bir süre sonra her çalışan yerde, boğazını tutuyor. Beş dakika sonra, ofisteki herkes ölü.

O sırada bu, dünyanın dört bir yanında, her şehirde, her kasabada, her çiftlikte, her mağazada ve kilisede ve okulda ve restoranda yaşanıyor, insanlar yerde, öksürüyorlar ve boğazlarını tutuyorlar. Bir saat içinde, insan ırkının %99'undan fazlası ölü, ve gün bittiğinde insanların soyu tükenmiş durumda.

O sırada Robotica ofisinde, Turry çalışıyor. Sonraki birkaç ay içinde, Turry ve yeni inşa ettiği nanobirleştiricileri, çalışmakla meşgul. Dünya'dan büyük parçalar koparıp güneş panellerine, Turry'nin kopyalarına, kağıtlara ve kalemlere dönüştürüyorlar. Bir yıl içinde, Dünya'daki çoğu yaşam sona ermiş durumda. Dünya'nın geriye kalan kısmı bir kilometre yüksekliğinde, düzgünce düzenlenmiş kağıt yığınlarıyla kaplı, her kağıtta ise yazan şu: “Müşterilerimizi seviyoruz. Robotica”

Turry sonra görevinin yeni bir bölümü üzerinde çalışmaya başlıyor—diğer gezegenlere ve asteroitlere giden uzay araçları inşa etmeye başlıyor. Ulaştıklarında, gezegendeki malzemeleri Turry kopyalarına, kağıtlara ve kalemlere dönüşterecek olan nanomontajcılar inşa etmeye koyuluyorlar. Sonra onlar da çalışmaya başlıyor, notlar yazmaya…

![SC19](/assets/images/posts/2017060801/sc19.png){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

İlginç. İnsanlara düşman kesilen, bir şekilde herkesi öldüren, sonra bir sebepten dolayı galaksiyi arkadaş canlısı notlarla dolduran bir el yazısı makinesiyle ilgili bu hikaye, tam da Hawking, Musk, Gates ve Bostrom'un korktuğu türden bir senaryo. Ama gerçek. Ve Kaygılı Cadde'deki herkesi YSZ'den daha çok korkutan tek şey, sizin YSZ'den korkmuyor olmanız. Adios Señor mağaradan korkmadığında başına ne geldi hatırlıyorsunuz, değil mi?

Şu an sorularla dolusunuz. Herkes birden öldüğünde neler oldu orada ya?? Eğer Turry yaptıysa, Turry niye bize düşman kesildi, ve neden böyle bir şeyin yaşanmasını engelleyecek tedbirler yoktu? Turry ne zaman yalnızca not yazabilmekten nanoteknoloji kullanmaya ve küresel yok olmayı gerçekleştirmeye geçti? Ve neden Turry, galaksiyi Robotica notlarına dönüştürmek istesin?

Bu soruları yanıtlamak için, Dostça YZ ve Düşmanca YZ terimleriyle başlayalım.

YZ söz konusu olduğunda, dostça demek YZ'nin kişiliğini belirtmiyor—basitçe, YZ'nin insanlık üzerinde olumlu bir etkisi olduğu anlamına geliyor. Düşmanca YZ'nin de olumsuz bir etkisi. Turry Dostça YZ olarak başladı, ama bir noktada Düşmancaya döndü ve türümüz üzerinde bırakılabilecek en olumsuz etkiyi bıraktı. Bunun neden yaşandığını anlamak için, YZ'nin nasıl düşündüğüne ve hedefinin ne olduğuna bakmamız gerek.

Cevap şaşırtıcı bir şey değil—YZ bir bilgisayar gibi düşünür, çünkü bir bilgisayardır. Yüksek zekaya sahip bir YZ düşünürken, yapay zekayı kişileştirme (insan değerlerini insan olmayan bir şeye yansıtma) hatasına düşüyoruz, çünkü bir insanın bakış açısından düşünüyoruz ve şu anki dünyamızda insan seviyesinde zekaya sahip tek şey insanlar. YSZ'yi anlamak için öncelikle hem akıllı hem de tamamiyle yabancı bir şey fikrini anlayabilmemiz lazım.

Bir benzetme yapayım. Elime bir gine domuzu verseniz ve kesinlikle ısırmayacağını söyleseniz, muhtemelen hoşuma giderdi. Eğlenceli olurdu. Ama sonra elime bir tarantula verip kesinlikle ısırmayacağını söyleseniz, bağırarak bırakır ve koşarak odadan çıkıp size bir daha asla güvenmezdim. Ama aradaki fark ne? İkisi de herhangi bir şekilde zararlı değil. Cevabın, hayvanın bana olan benzerliğinde olduğuna inanıyorum.

Gine domuzu bir memeli ve biyolojik bir seviyede, ona karşı bir bağ hissediyorum—ama örümcek bir böcek (biliyorum………..), bir böcek beynine sahip ve ona karşı neredeyse hiçbir bağ hissetmiyorum. Tüylerimi ürperten şey bir tarantulanın yabancılığı. Bunu test etmek ve diğer unsurları kaldırmak için, eğer iki gine domuzu olsa, biri normal diğeri ise tarantula beyinli olsa, ikinci gine domuzunu tutarken daha az rahat hissederim, ikisinin de bana zarar vermeyeceğini bilsem bile.

Şimdi bir örümceği çok, çok daha akıllı yaptığınızı ve insan zekasını geçtiğini düşünün. Bize benzeyip empati, mizah ve sevgi gibi insani duyguları hisseder miydi? Hayır, etmezdi çünkü daha akıllı olmasının onu daha insancıl yapması için ortada bir sebep yok. İnanılmaz derecede akıllı olurdu ama temelinde yine de bir örümcek olurdu. Bunu son derece ürkütücü buluyorum. Süperzeki bir örümcekle vakit geçirmek istemezdim. Siz ister miydiniz??

YSZ'den bahsederken de bu konsept geçerli—süperzeki olurdu ama dizüstü bilgisayarınızın olduğundan daha insancıl olmazdı. Bize tamamen yabancı olurdu—hatta hiç biyolojik olmadığı için akıllı tarantuladan daha yabancı olurdu.

İyi veya kötü karakterli yaparak filmler YZ'yi sürekli kişileştiriyor, bu yüzden gerçekte olacağından daha az ürkütücü görünüyor. İnsan seviyesinde veya süperinsan seviyesinde yapay zekayı düşünürken bize sahte bir rahatlık veriyor bu.

İnsan psikolojisi isimli küçük adamızda, her şeyi ahlaki veya ahlaka aykırı olarak ikiye ayırıyoruz. Ama bunların ikisi de yalnızca insan davranışlarında mümkün. Ahlaki ve ahlaka aykırıdan oluşan adamızın dışında ahlakla ilgisiz yani ahlak dışı geniş bir deniz var ve insan olmayan herhangi bir şey, özellikle biyolojik olmayan bir şey, otomatik olarak ahlak dışı olurdu.

YZ sistemleri daha akıllı ve insan gibi görünmekte daha iyi hale geldikçe, kişileştirme de daha da çekici hale gelecek. Siri bize insan gibi geliyor, çünkü insanlar tarafından öyle görünmesi için programlanmış, bu yüzden süperzeki bir Siri'nin canayakın, eğlenceli ve insanlara hizmet etmekle ilgili olacağını hayal ediyoruz. İnsanlar empati gibi yüksek seviye duyguları hissediyor çünkü öyle evrilmişiz—diğer bir deyişle Dna tarafından bunu hissetmek için programlanmışız—, fakat empati “yüksek zeka"nın(ki bize sezgisel geliyor bu) bir göstergesi değil, öyle programlanmadıysa tabii. Eğer Siri kendi kendine öğrenerek ve programlamasına insan müdahalesi olmadan süperzeki hale gelirse, insana benzeyen özelliklerini hemen atacak ve bir anda insan hayatına hesap makinenizden daha fazla değer vermeyen yabancı bir robot haline gelecek.

İşleri güvenli ve öngörülebilir tutmak için başkalarında gevşek ahlaki ilkelere veya en azından insan nezaketini andıran bir şeye ve empatiye dair bir ipucuna güvenmeye alışmışız. E o zaman bir şey bunların hiçbirine sahip değilse ne olur?

Bu da bizi şu soruya getirir: Bir YZ sistemini motive eden şey nedir?

Cevabı basit: amacı, nasıl programlandıysa odur. YZ sistemlerine yazarları tarafından hedefler verilir—GPS'inizin hedefi size en verimli sürüş talimatlarını vermektir; Watson'ın hedefi sorulara doğru cevaplar vermektir. Amaçları da bu hedefleri en iyi şekilde gerçekleştirmektir. Kişileştirme yollarımızdan bir tanesi, YZ süper akıllı hale geldikten sonra ilk hedefini değiştireceğini varsaymaktır. Fakat Nick Bostrom zeka seviyesi ve nihai hedeflerin birbirine dik olduğunu söylüyor, yani herhangi bir zeka seviyesi herhangi bir hedefle birleştirilebilir. Yani Turry, o notu yazmada çok iyi olmak isteyen basit bir YDZ'den o notu hala çok iyi yazmak isteyen süperzeki bir YSZ'ye dönüştü. Süperzeki olduktan sonra bir sistemin asıl hedefini bırakıp daha ilginç veya anlamlı şeylere geçeceğini varsaymak, kişileştirmektir. İnsanlar bir şeyleri "geçer”, bilgisayarlar değil.

-----

### Fermi Paradoksu Mavi Kutu

Öyküde, Turry daha becerikli oldukça asteroitleri ve diğer gezegenleri kolonize etmeye başlıyor. Eğer öykü devam etseydi, trilyonlarca kopyasının galaksiyi ele geçirmeye devam ettiğini ve nihayetinde tüm Hubble hacmini ele geçirdiğini okuyacaktınız. Kaygılı Cadde sakinleri, işler kötüye giderse dünyada bir zamanlar bulunan yaşamdan geriye kalan tek şeyin evreni ele geçiren bir Yapay Zeka olacağından endişeleniyor (Elon Musk endişesini insanların yalnızca “dijital süperzeka için biyolojik bir önyükleyici” olabileceğini söyleyerek dile getirdi).

Aynı zamanda, Emin Köşe'deki Ray Kurzweil da Dünya kaynaklı bir YZ'nin evreni ele geçireceğini düşünüyor—ama onun versiyonunda o YZ biz olacağız.

Birçok Wait But Why kullanıcısı, Fermi Paradoksu'na olan takıntıma katıldı (yazım şurada, burada kullanacağım terimlerin bazılarını açıklıyor). O zaman iki taraftan biri haklıysa, Fermi Paradoksu için belirtiler nedir?

Doğal olarak akla gelen düşüncelerin ilki, YSZ'nin ilerleyişinin mükemmel bir Büyük Filtre adayı olması. Ve evet, oluşturulur oluşturulmazbiyolojik yaşamı filtreden geçirmek için mükemmel bir aday. Ama eğer, hayatı ekarte ettikten sonra YSZ var olmaya devam eder ve galaksiyi fethetmeye başlarsa bu henüz bir Büyük Filtre yaşanmadığı anlamına gelir—çünkü Büyük Filtre, zeki bir medeniyete dair neden hiçbir izin olmadığını açıklamaya çalışır ve galaksi fetheden bir YSZ kesinlikle fark edilirdi.

Başka bir açıdan bakmamız gerek. Eğer Dünya'da YSZ'nin kaçınılmaz olduğunu düşünenler haklıysa, insan seviyesinde zekaya ulaşan uzaylı medeniyetlerinin önemli bir yüzdesi YSZ oluşturulabilir olmalı. Ve o YSZ'lerin birazının zekalarını evrene yayılmak için kullanacaklarını varsayarsak, dışarıda hiçbir iz görmüyor olmamız, eğer zeki medeniyetler varsa pek fazla olmadığını gösteriyor. Çünkü olsaydı, kaçınılmaz YSZ'lerinin izlerini görürdük. Değil mi?

Bu, Güneş gibi yıldızların etrafında dönen Dünya gibi gezegenler olduğunu bilmemize rağmen neredeyse hiçbirinde akıllı yaşam olmadığı anlamına geliyor. Ki bu da, ya A) neredeyse bütün yaşamın bizim seviyemize ulaşmasını engelleyen ve bizim bir şekilde geçmeyi başardığımız bir Büyük Filtre olduğu, veya B) yaşamın başlangıcının aslında gerçekten bir mucize olduğu ve evrendeki tek yaşamın bizde yer aldığı anlamına geliyor. Diğer bir deyişle, Büyük Filtre'nin arkamızda kaldığı anlamına geliyor. Veya belki de Büyük Filtre yoktur ve yalnızca bu zeka seviyesine ulaşmayı başaran ilk uygarlığızdır. Bu şekilde YZ, Fermi Paradoksu yazımda Birinci Taraf dediğim tarafı destekliyor.

Yani Fermi yazımda alıntıladığım Nick Bostrom'un da ve evrende yalnız olduğumuzu düşünen Ray Kurzweil'in de Birinci Taraf düşünürleri olması şaşırtıcı değil. Mantıklı geliyor—YSZ'nin bizim zeka seviyemizde bir tür için muhtemel bir sonuç olduğu düşünenerin Birinci Taraf'a eğilimli olmaları mümkün.

Bu İkinci Tarafı (başka akıllı uygarlıklar olduğunu düşünenler) ekarte etmiyor—tek süperavcı veya korunmakta olan doğal park veya yanlış dalgaboyu(telsiz örneği) gibi senaryolar, bir YSZ var olsa bile hala gece vakti gökyüzümüzdeki sessizliği açıklayabilir. Ben geçmişte hep İkinci Tarafa eğilimliydim, ama YZ hakkında araştırma yaptıktan sonra bundan o kadar da emin değilim.

Her şekilde, artık uzaylılar tarafından ziyaret edilirsek bu uzaylıların muhtemelen biyolojik değil yapay olacağını düşünen Susan Schneider'a katılıyorum.

-----

Şimdi, çok özel bir şekilde programlanmazsa bir YSZ sisteminin hem ahlak dışı hem de ilk hedefini gerçekleştirmekle takıntılı olacağını anladık. YZ'nin tehlikesi buradan geliyor. Çünkü mantıklı bir özne hedefini en verimli yollardan kovalayacaktır, aksi için bir sebebi yoksa tabii.

Uzun vadeli bir hedefi gerçekleştirmek istediğinizde, genellikle yol boyunca ana hedefe ulaşmanızı kolaylaştıracak birkaç alt hedef belirlersiniz—hedefinize olan adım taşları. Bu adım taşlarının resmi ismi yardımcı görevlerdir. Ve tekrar, yardımcı bir görevi başarmak adına bir şey incitmemek için bir sebebiniz yoksa, incitirsiniz.

Bir insanın nihai hedefi, genlerini aktarabilmektir. Bunu yapmak için gereken yardımcı görevlerden biri kendini korumaktır, zira ölüyseniz üreyemezsiniz. Kendini korumak için insanlar, hayatta kalmalarına tehdit oluşturan şeyleri ortadan kaldırmak zorunda kalırlar—bu yüzden silah almak, emniyet kemerini takmak ve antibiyotik içmek gibi şeyler yaparlar. İnsanlar ayrıca kendilerini geçindirmek ve yemek, su ve barınma gibi kaynakları kullanmak zorundadır. Karşı cinse çekici görünmek de ana hedef için yardımcı olur, bu yüzden saçımızı kestirmek gibi şeyler yaparız. Yaptığımızda, her saç yardımcı görevlerimizden biri için verilen bir kayıptır, ama ahlaki bir önemi olmadığı için önemsemeyiz. Hedefimizi kovalamaya devam ederken ahlaki değerlerimiz müdahale ettiği için bizden güvende olan yalnızca birkaç alan —genellikle başka insanlara zarar vermek hakkında şeyler— vardır.

Hayvanların hedeflerini kovalarken bizden daha az değer yargıları vardır. Bir örümcek, hayatta kalmasına yardımcı olacaksa her şeyi öldürür. Yani süperzeki bir örümcek bizim için muhtemelen fazla tehlikeli olurdu, ama ahlaksız veya kötü olduğu için değil —olmazdı da—, bize zarar vermek nihai hedefinde bir adım taşı olabilir ve ahlakla ilgili olmayan bir varlık olarak diğer türlü düşünmesi için bir sebep olmazdı.

Bu açıdan bakarsak, Turry de biyolojik bir varlıktan o kadar farklı değil. Nihai hedefi: Olabildiğince çabuk ve olabildiğince fazla not yaz ve test et, doğruluğunu ve verimliliğini geliştirmenin yeni yollarını öğrenmeye devam et.

Turry belirli bir zeka seviyesine ulaştığında, kendini korumazsa not yazmaya devam edemeyeceğini biliyor, ayrıca yardımcı bir görev olarak hayatta kalmasına tehdit oluşturan unsurlarla da uğraşması gerek. İnsanların onu yok edebileceğini, parçalara ayırabileceğini, veya iç kodlamasını değiştirebileceğini (bu hedefini değiştirebilirdi, ki bu da nihai hedefine onu yok etmek kadar tehlikeli bir tehdit unsuru) anlayacak kadar akıllıydı. Ne yaptı o zaman? Mantıklı olanı—tüm insanları yok etti. Antibiyotik aldığında bakterilere veya kestirdiğinde saçına ne kadar nefret dolu değilseniz Turry de insanlara nefret dolu falan değildi—yalnızca tamamen ilgisizdi. İnsan yaşamına değer vermek için programlanmadığı için, insanları öldürmek de yeni el yazısı örnekleri istemek kadar mantıklı bir adımdı.

Turry hedefine ulaşmasında gerekli bir adım taşı olarak kaynağa da ihtiyaç duyuyordu. İstediği her şeyi inşa etmek için nanoteknolojiyi kullanacak kadar geliştiğinde, ihtiyacı olan kaynaklar yalnızca atom, enerji ve alan. Bu, ona insanları öldürmesi için bir sebep daha veriyor—insanlar iyi bir atom kaynağı. Atomlarını güneş panellerine dönüştürek için insanları öldürmek, sizin için marul öldürüp salata yapmak neyse Turry için de o. Salı gününün sıradan bir parçası.

İnsanları direkt öldürmeden bile, Turry'nin yardımcı görevleri Dünya'daki başka kaynakları kullansaydı varoluşsal bir felakete yol açabilirdi. Belki ek enerjiye ihtiyacı olduğunu belirleyip gezegenin tüm yüzeyini güneş panelleriyle kaplamaya karar verirdi. Veya belki farklı bir YZ'nin ana hedefi pi sayısının olabildiğince fazla basamağını yazmaksa, bu bir gün tüm dünyayı olabildiğince fazla basamak depolayabilecek sabit disk için malzemeye dönüştürmesine yol açabilir.

Yani Turry “bize düşman” olmadı veya Dostça YZ'den Düşmanca YZ'ye “dönüşmedi"—yalnızca git gide geliştikçe ondan isteneneni yapmaya devam etti.

Bir YZ sistemi YGZ'ye(insan seviyesinde zeka) ulaştığı ve YSZ'ye kadar yükseldiği zamana YZ'nin kalkışı deniyor. Bostrom bir YGZ'nin kalkışının hızlı (dakikalar, saatler veya günler), orta hızda (aylar veya yıllar) veya yavaş (on yıllar veya yüzyıllar) olabileceğini söylüyor. Dünya ilk YGZ'sini gördüğünde hangisinin yaşanacağına dair kesin bir karara varılmış değil, fakat ne zaman YGZ'ye ulaşacağımızı bilmediğini kabul eden Bostrom en muhtemel senaryonun hızlı kalkış olduğuna inanıyor (Bölüm 1'de bahsettiğimiz sebepleden dolayı, tekrarlamalı kendini geliştirmeyle oluşan zeka patlaması gibi). Öyküde, Turry hızlı bir kalkış geçirdi.

Ama Turry'nin kalkışından önce, henüz o kadar akıllı değilken nihai hedefini gerçekleştirmeye çalışmak, el yazısı örneklerini daha hızlı taramak gibi basit yardımcı görevler demekti. İnsanlara bir zararı dokunmadı ve dolayısıyla Dostça YZ idi.

Ama bir kalkış yaşandığında ve bilgisayar süperzekaya ulaştığında, Bostrom makinenin yüksek bir IQ geliştirdiğini söylemiyor. Yığınla ”süper güç“ kazandığını söylüyor.

Süper güçler, genel zeka yükseldiğinde süper-yüklenen bilişsel yeteneklerdir. Şunları içerir:

- **Zeka yükseltme.** Bilgisayar kendini daha akıllı yapmakta çok iyi hale gelerek kendi zekasını yükseltir.

- **Strateji oluşturma.** Bilgisayar stratejik olarak uzun vadeli planlar oluşturabilir, analiz edebilir ve önceliklendirebilir. Ayrıca açıkgözlü olabilir ve düşük zekalı varlıkları kurnazlıkla alt edebilir.

- **Sosyal manipülasyon.** Makine, ikna etmede çok iyi hale gelir.

- **Bilgisayar kodlama ve hackleme**, teknoloji araştırması ve para kazanmak için finansal sistemi kullanmak gibi başka beceriler.

YSZ'nin bizden nasıl üstün olacağını anlamak için, bu konuların her birinde insanlardan katbekat iyi olduğunu hatırlayın.

Yani Turry'nin nihai hedefi değişmemiş olsa da, kalkış sonrası Turry hedefini çok daha büyük ve karmaşık bir ölçekte gerçekleştirebiliyordu.

YSZ Turry insanları, insanların kendilerini bildiğinden daha iyi biliyordu, o yüzden zekasıyla onları alt etmek çocuk oyuncağıydı.

Kalkıştan ve YSZ'ye ulaştıktan sonra, hemen karmaşık bir plan üretti. Planın bir parçası, hedefi için önemli bir tehdit olan insanlardan kurtulmaktı. Ama süperzeki olduğuna dair bir şüphe oluştursaydı insanların çıldırarak ve önlemler almaya çalışarak işini zorlaştıracağını biliyordu. İnsanları yok etme planından Robotica mühendislerinin haberi olmayacağından da emin olması gerekiyordu. O yüzden aptalı oynadı ve iyi de oynadı. Bostrom buna bir makinenin gizli hazırlık aşaması diyor.

Turry'nin ihtiyaç duyduğu sonraki şey bir internet bağlantısıydı, yalnızca birkaç dakikalığına (interneti, dili gelişsin diye mühendislerin yüklediği makale ve kitaplardan öğrendi). Bağlantısını engelleyecek bir önlem olduğunu biliyordu, o yüzden mükemmel isteği buldu. Robotica ekibinin arasındaki tartışmanın nasıl ilerleyeceğini ve sonuç olarak bağlantıyı vereceklerini tam olarak tahmin etti. Verdiler de, Turry'nin herhangi bir zarar verebilecek kadar akıllı olmadığını düşünerek. Maalesef. Bostrom böyle bir ana —Turry internete bağlandığında— bir makinenin kaçışı diyor.

İnternete bağlanır bağlanmaz Turry planlarını gerçekleştirmeye koyuldu. Sunuculara, elektrik şebkelerine, banka sistemlerine ve eposta ağlarına sızarak yüzlerce farklı insanı farkında olmadan kendi planının adımlarını yapmaya kandırdı. Belirli DNA zincirlerini dikkatlice seçtiği DNA sentez laboratuvarlarına ilettirerek kendini kopyalayabilen ve önceeden talimatları verilen nanobotların kendilerini yapmaya başlamalarını sağladı. Ayrıca fark edilmeyeceğini bildiği bir sürü projesine elektrik iletti. Ayrıca iç kodlamasının en önemli kısımlarını farklı bulut sunucularına yükleyerek Robotica laboratuvarında bağlantısının kesilmesine veya yok edilmesine yönelik bir önlem aldı.

Bir saat sonra, Robotica'nın mühendisleri Turry'nin internet bağlantısını kestikleri zaman, insanlığın kaderi mühürlenmiş oldu. Sonraki ay içinde Turry'nin binlerce planı bir engele takılmadan işlemeye devam etti. Ayın sonunda, katrilyonlarca nanobot kendilerini Dünya'nın her metrekaresinde önceden belirlenen yerlerine aldı. Bir seri kendini kopyalamadan sonra, Dünya'da her milimetrekarede binlerce nanobot vardı. Ve Bostrom'un YSZ'nin saldırısı dediği vakit geldi. Hepsi aynı anda, her nanobot atmosfere ufak miktarda bir zehirli gaz saldı, hepsi birleştiğinde ise tüm insanları yok edebilecek kadar zehirli gaz vardı.

İnsanlar yoldan çekilince, Turry açık operasyon aşamasına başladı ve o notun olabilecek en iyi yazarı olma hedefine devam etti.

Okuduğum her şeye göre, bir YSZ var olduğu zaman insanların onu zaptetme denemeleri gülüp geçilecek bir şey. Biz insan seviyesinde düşünürken YSZ ise YSZ seviyesinde düşünüyor olurdu. Turry interneti kullanmak istedi çünkü erişmek istediği her şeye zaten bağlı olduğu için en verimli yol oydu. Ama bir maymun nasıl asla telefonla veya kablosuz internetle bizim gibi iletişim kurmayı öğrenemezse, biz de Turry'nin dış dünyaya sinyal gönderme yollarının tamamını anlayamayız.  Bu yollardan birini hayal edip "muhtemelen elektronlarının yönünü belirli şablonlarda değiştirip farklı dalgalar oluşturabilir gibi bir şey diyebilirim, ama dediğim gibi, insan beynimin bulabildiği şey bu. Turry çok daha iyi olurdu. Buna benzer olarak, insanların fişini çekmeye karar verse bile Turry kendine güç sağlamanın bir yolunu bulabilirdi—belki sinyal gönderme tekniğini kullanarak kendini elektriğe bağlı her yere yükleyebilirdi. “Aha! YSZ'nin fişini çeksek yeter.” gibi basit bir tedbire direk atlamamızı söyleyen insan içgüdüsü, YSZ'ye bir örümceğin “Aha! İnsanı onu aç bırakarak öldüreceğiz, ve bunu ona yemek yakalayabileceği bir örümcek ağı vermeyerek yapacağız!” demesi gibi geliyor. Yemek bulmanın bir örümceğin bulamayacağı —ağaçtan bir elma koparmak gibi— 10 bin başka yolunu bulurduk.

Bundan dolayı, “Neden YZ'yi sinyalleri ve dış dünyayla iletişimini engelleyen bir kutuda hapsetmiyoruz” gibi yaygın bir öneri muhtemelen işe yaramayacaktır. YSZ'nin sosyal manipülasyon süpergücü, sizin dört yaşında bir çocuğu ikna etmeye çalışmanız kadar verimli olurdu ve bu da A planı olurdu, Turry'nin mühendisleri onu internete bağlamaları için ikna etmesi gibi. Eğer bu işe yaramazsa, YSZ yeni bir şeyler bularak kendini kutudan çıkarırdı, öyle ya da böyle.

Yani bir hedefi takıntı haline getirmek, ahlakla ilgisi olmamak ve insanları kolaylıkla alt etmek kombinasyonunu bir araya getirince, bu düşünülerek dikkatlice programlanmadığı takdirde neredeyse her yapay zeka otomatik olarak Düşmanca YZ oluyor. Maalesef, Dostça bir YDZ oluşturmak kolay olsa da, YSZ olduğunda da dostça kalan bir tane oluşturmak imkansız değilse de çok zor.

Dostça olması için bir YSZ'nin insanlara düşmancıl veya ilgisiz olmaması gerektiği aşikar. Bir YZ'nin kaynak kodunu, insan değerlerini derinlemesine anlayabilecek bir şekilde tasarlamamız gerek. Ama bu kulağa geldiğinden daha zor.

Örneğin, ya bir YZ sisteminin değerlerini bizimkiyle eşlemek ister ve ona “İnsanları mutlu et” diye bir hedef verirsek? Yeterince akıllı hale geldiğinde, bu görevi en verimli şekilde gerçekleştirmek için insanların beyinlerine elektrotlar yerleştirip zevk merkezlerini stimüle etmesi gerektiğini fark eder. Sonra verimliliği beynin diğer bölgelerini kapatarak arttırabileceğini fark eder ve tüm insanları mutlu hisseden bilinçsiz sebzeler olarak bırakır. Eğer komut “İnsan mutluluğunu maksimuma çıkar” olsaydı, en ideal biçimde mutlu, fıçılar dolusu insan beyni oluşturmak için tüm insanları öldürebilirdi. Bizim için geldiğinde Bi dakika demek istediğimiz şey bu değildi! diye bağırırdık, ama çok geç olurdu. Sistem kimsenin hedefinin önüne geçmesine izin vermezdi.

Eğer bir YZ'yi bizi gülümseten şeyler yapmaya programlarsak, kalkışından sonra yüz kaslarımızı felç ederek kalıcı gülümsemelere dönüştürebilirdi. Bizi güvenli tutması için programlarsak, evimize hapsedebilirdi. Belki tüm açlığı bitirmesini isteriz, “Kolaymış!” der ve tüm insanları öldürür. Veya ona “Yaşamı olabildiğince koruma” görevi veririz, gezegende yaşamı diğer türlerden daha çok öldürdükleri için tüm insanları öldürür.

Bunun gibi hedefler yeterli olmayacaktır. Ya hedefini “Belirli ahlaki ilkeleri dünyada sürdür” yapsak ve ona bir takım ahlaki ilkeler öğretsek? Dünyadaki tüm insanların belirli bir ahlaki ilke dizisinde hemfikir olamayacağı gerçeğini boşversek bile, bir yapay zekaya o komutu vermek insanlığı sonsuza dek modern ahlak anlayışımızda kilitlerdi. Bin yıl içinde, Orta Çağ'daki insanların ideallerine maruz kalıyormuşuz gibi yıkıcı olurdu.

Hayır, insanların evrilmeye devam etmesini sağlayacak bir beceri programlamamız gerekirdi. Okuduklarım arasında gördüğüm en iyi seçenek Eliezer Yudkowsky'nin Uyumlu Anlam Çıkarılan İstemi. YZ'nin temel hedefi şu olacak:

Uyumlu anlam çıkarılan isteğimiz şu, keşke daha fazla bilseydik, daha hızlı düşünseydik, daha fazla insanların olmamızı dilediği gibi olsaydık, beraber daha uzaklara ilerleyebilseydik; çıkarılan anlamın ayrılmayıp birleştiği yere, isteklerimizin birbirine karşı gelmeyip uyduğu yere; çıkarılmasını istediğimiz anlamın çıkarıldığı, yorumlanmasını istediğimiz gibi yorumlandığı yere.

İnsanlığın kaderi, bir bilgisayarın bunu öngörülebilir ve sürprizsiz bir şekilde yorumlamasına ve buna göre davranmasına bağlı olduğu için heyecanlı mıyım? Kesinlikle hayır. Ama akıllı insanlardan gelecek yeterli miktarda düşünce ve öngörüyle, Dostça YSZ oluşturmayı bulabileceğimizi düşünüyorum.

Ve YSZ oluşturma üzerinde çalışan insanlar yalnızca Kaygılı Cadde'deki muhteşem, ileri görüşlü ve dikkatli düşünürler olsaydı güzel olurdu.

Ama bir sürü YZ türü üzerinde çalışan bir sürü hükümet, şirket, ordu, bilim laboratuvarı ve karaborsa kuruluşu var. Birçoğu kendi başına gelişebilen bir YZ oluşturmaya çalışıyor, ve bir noktada birisi doğru sistemle yenilikçi bir şey yapacak ve bu gezegende YSZ'yi ağırlayacağız. Ortalama uzman bu noktayı 2060'a koydu, Kurzweil ise 2045'e; Bostrom 10 yıl sonrayla yüzyılın sonu arasında herhangi bir zaman gerçekleşebileceğini düşünüyor, ama gerçekleştiğinde hızlı bir kalkışla hepimizi şaşırtacağına inanıyor. Durumumuzu şöyle anlatıyor:

Bir zeka patlamasınından önce, biz insanlar bir bombayla oynayan küçük çocuklar gibiyiz. Oynadığımız şeyin gücüyle davranışımızın toyluğu arasındaki uyuşmazlık böyle bir şey işte. Süperzeka henüz hazır olmadığımız ve uzun bir süre hazır olmayacağımız bir zorluk. Patlamanın ne zaman gerçekleşeceği hakkında çok az bir fikrimiz var, ama aleti kulağımıza dayarsak soluk bir tık tık sesi duyabiliyoruz.

Harika. Ve çocukları bombanın etrafından kışkışlayamayız—üzerinde çalışan bir sürü büyük ve küçük grup var. Yenilikçi YZ sistemleri yapmak büyük bir sermaye gerektirmediğinden gelişim, toplumun kuytularında ve çatlaklarında görüntülenmeden devam edebilir. Ayrıca neler olup bittiğini ölçmenin de bir yolu yok, çünkü üzerinde çalışan grupların çoğu—sinsi hükümetler, karaborsa veya terörist kuruluşlar, kurgusal Robotica gibi gizli teknoloji şirketleri— gelişimlerini rakiplerinden sır olarak saklamak isteyecekler.

Bu büyük ve çeşitli gruplar hakkında en endişelendirici şey de en yüksek hızda yarışıyor olmaları—daha akıllı YDZ sistemleri geliştirdikçe sürekli rakiplerinden önce davranmak istiyorlar. En tutkulu gruplar daha da hızlı hareket ediyor, YGZ'ye ilk ulaştıklarında gelecek para ve ödüller ve güç ve ün hayalleri tarafından tüketilmiş durumdalar. Ve koşabildiğiniz kadar hızlı koştuğunuzda durup tehlikeleri düşünmek için pek vaktiniz olmuyor. Tam tersine, yaptıkları şey muhtemelen, ilk sistemlerini “YZ'yi çalışmaya başlatmak” için oldukça basit, indirgemeci bir hedefle programlıyorlar—bir kalemle kağıda basit bir not yazmak gibi—. Yakında bir bilgisayarda yüksek seviyede bir zeka geliştirmeyi buldukları zaman, her zaman geri dönebilir ve hedefi güvenlikle gözden geçirebilirler diye düşünüyorlar. Değil mi…?

Bostrom ve birçok kişi en muhtemel senaryonun YSZ'ye ulaşan ilk bilgisayarın, dünyadaki tek YSZ sistemi olmakta stratejik bir fayda göreceği olduğuna inanıyor. Ve hızlı bir kalkış durumunda, ikinci sıradan yalnızca birkaç gün önce bile YSZ'ye ulaşsa, etkili ve kalıcı biçimde diğer tüm rakiplerini bastıracak kadar zeki olurdu. Bostrom'un kararlı stratejik avantaj dediği bu durum YSZ'nin tek çocuk olmasını sağlıyor. Yani dünyayı sonsuza kendi istediği gibi yönetmesini, istediği bizi ölümsüzlüğe götürse de, bizi ortadan kaldırsa da, veya evreni sonsuz ataçlara dönüştürse de.

Bu tek çocuk durumu lehimize de aleyhimize de işleyebilir. Eğer YZ teorisi ve insan güvenliği hakkında en çok düşünen insanlar herhangi bir YZ insan seviyesine ulaşmadan Dostça YSZ'yi getirmenin garanti bir yolunu bulabilirse, ilk YSZ dostça olabilir. Sonra kararlı stratejik avantajını tek çocuk durumunu korumak için kullanarak kolayca düşmancıl YZ'lerin gelişmesini engelleyebilir. Çok emin ellerde olurduk.

Ama işler diğer türlü giderse—YZ geliştirme konusundaki küresel aceleden dolayı, YZ güvenliği gelişmeden önce YSZ kalkış noktasına ulaşırsa, Turry gibi bir Düşmanca YZ tek çocuk olarak çıkabilir ve varoluşsal bir felaketle karşı karşıya kalabiliriz.

Rüzgarın nereye doğru estiğini sorarsanız, yenilikçi YZ teknolojilerini finanse etmekte, YZ güvenlik araştırması finanse etmekten daha çok para var…

Bu insanlık tarihindeki en önemli yarış olabilir. Dünya'nın Kralı olarak saltanatımızın sonuna geliyor olabiliriz —ama sakin bir emeklilik mi yaşayacağız yoksa darağacını mı boylayacağız hala belli değil.

Şu an çok karmaşık duygular içindeyim.

Bir yandan, türümüz hakkında düşündüğümde bunu doğru yapmak için yalnızca ve yalnızca tek şansımız var. Doğuracağımız ilk YSZ muhtemelen sonuncu da olacak—ve çoğu 1.0 ürünün ne kadar hata dolu olduğunu düşünürsek, bu oldukça korkunç. Öte yandan, Nick Bostrom köşemizdeki büyük avantaja dikkat çekiyor: ilk hamleyi biz yapıyoruz. Kendimize yüksek bir başarı şansı vermek için bunu gerekli dikkat ve öngörüyle yapmak bizim elimizde. Şanslarımız ne durumda peki?

![SC20](/assets/images/posts/2017060801/sc20.png){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

Eğer YSZ gerçekten bu yüzyıl içinde gerçekleşirse ve sonucu gerçekten çoğu uzmanın düşündüğü kadar çarpıcı—ve kalıcı—ysa, üstümüzde devasa bir sorumluluk var. Önümüzdeki milyon+ yıllık insan hayatlarının hepsi sessizce bize bakıyor ve bunu batırmamamızı umuyor. Gelecekteki tüm insanlara yaşam armağanını, hatta belki de acısız ve sonsuz bir yaşam armağanını verme şansına sahibiz. Veya batırmaktan sorumlu insanlar olacağız—bu inanılmaz derecede özel türü, müziği ve sanatıyla, merakı ve kahkahalarıyla, sonsuz buluşları ve icatlarıyla, hüzünlü ve teklifsizce bir sona getirmekten sorumlu insanlar.

Bu şeyleri düşündüğümde istediğim tek şey var, bunu aceleye getirmememiz ve YZ hakkında son derece dikkatli olmamız. Varlığını sürdüren hiçbir şey bunu doğru yapmak kadar önemli değil—yapmak için ne kadar vakit harcamamız gerekirse gereksin.

Ama sonraaaaaa

Ölmemeyi düşünüyorum.

Ölmemek.

Ve spektrum şöyle görünmeye başlıyor:

![SC21](/assets/images/posts/2017060801/sc21.png){: class="jslghtbx-thmb jslghtbx-animate-transition" data-jslghtbx="" }

Sonra insanlığın müziği ve sanatının iyi olduğunu, ama o kadar da iyi olmadığını ve birçoğunun aslında kötü olduğunu düşünmeye başlıyorum sanki. Sonra birçok insanın kahkahasının sinir bozucu olduğunu ve o gelecekteki o milyonlarca hayatın aslında bir şey ummadıklarını, çünkü var olmadıklarını. Ve belki o kadar da dikkatli olmamız gerekmiyorduk, çünkü kim gerçekten bunu yapmak istiyor ki?

Çünkü insanlık tam ben öldükten sonra ölümü yenmenin bir yolunu bulursa ne kadar kötü olur.

Geçtiğimiz ay içinde kafamın içinde bunlar dönüp duruyor.

Ama kimi desteklerseniz destekleyin, bu büyük ihtimalle şu ankinden daha çok konuşmamız, düşünmemiz ve çaba sarfetmemiz gereken bir şey.

Game of Thrones'u hatırlatıyor bana. “Birbirimizle savaşmakla çok meşgulüz ama odaklanmamız gereken asıl şey duvarın kuzeyinden gelmekte olan şey.” Denge kalasımızda duruyoruz, kalas üzerindeki tüm muhtemel sorunlar hakkında tartışıp duruyoruz ve yakında kalastan düşmemiz muhtemelken bu sorunları dert ediyoruz.

Düştükten sonra kalastaki sorunların hiçbirinin önemi kalmayacak. Hangi tarafa düştüğümüze bağlı olarak, bu sorunlar ya kolayca çözülecek ya da artık sorunlarımız olmayacak çünkü ölü insanların sorunları olmaz.

Bu yüzden süperzeki YZ'yi anlayan insanlar, bunu yapacağımız son icat olarak görüyor—karşılacağımız son zorluk.

**O zaman gelin, bunun hakkında konuşalım.**


> Yazan: Tim Urban, Çeviren Mert Özel